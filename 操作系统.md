# 第 1 章  计算机系统概述

## 1.1 操作系统的基本概念

* 操作系统的概念：操作系统是指控制和管理整个计算机系统的**硬件与软件资源**，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便**接口**与环境的程序集合。操作系统是计算机系统中最基本的**系统软件**。
  * 接口：用户通过接口使用计算机，接口分为**命令接口**和**程序接口**。
    * 命令接口又分为**联机命令接口**（**交互式命令接口**）和**脱机命令接口**（**批处理命令接口**）。联机命令接口适用于分时或实时系统（“雇主”说一句话，"工人”做一件事，并做出反馈，这就强调了交互性），脱机命令接口适用于批处理系统（"雇主”把要"工人”做的事写在清单上，"工人”按照清单命令逐条完成这些事，这就是批处理）。
    * 程序接口由一组**系统调用**（**广义指令**）组成。
  * 没有任何软件支持的计算机称为**裸机**，它仅构成计算机系统的物质基础。覆盖了软件的机器称为**扩充机器**或**虚拟机**。操作系统将裸机改造成虚拟机。
* **操作系统的特征**：**并发、共享、虚拟和异步**。
  * 并发和并行：并发（Concurrence）是指多个事件在同一**时间间隔**内发生，并行是指在同一**时刻**进行多种工作。在多道程序环境下，一段时间内， 宏观上有多道程序在同时执行，而在每个时刻，*单处理机环境下实际仅能有一道程序执行*，因此微观上这些程序仍是分时交替执行的。操作系统的并发性是通过**分时**得以实现的。 
  * 共享：系统中的资源可供内存中多个并发执行的进程共同使用。共享可分为**互斥共享方式**和**同时访问方式**。和并发一样，互斥和同时访问都是指在一段时间内，而非真正意义上的同时刻。在一段时间内只允许互斥共享的资源称为**临界资源**。并发和共享是操作系统两个**最基本**的特征，两者之间互为存在的条件。
  * 虚拟：虚拟是指把一个物理上的实体变为若干逻辑上的对应物。用于实现虚拟的技术，称为**虚拟技术**。虚拟技术可分为**时分复用技术**（e.g. 虚拟处理器）和**空分复用技术**（e.g. 虚拟存储器）。
  * 异步：多道程序环境允许多个程序并发执行，但由于资源有限，进程的执行并不是一贯到底的，而是走走停停的，它以不可预知的速度向前推进，这就是进程的异步性。

* **操作系统的功能**：处理机管理、存储器管理、设备管理和文件管理。
  * 处理机管理：在多道程序环境下，处理机的分配和运行都以进程（或线程）为基本单位，因而*对处理机的管理可归结为对进程的管理*。
  * 存储器管理：方便用户使用及提高内存的利用率。
  * 文件管理：计算机中的信息都是以文件的形式存在的，操作系统中负责文件管理的部分称为**文件系统**。 
  * 设备管理：完成用户的I/O请求，方便用户使用各种设备，并提高设备的利用率。

## 1.2 操作系统发展历程

![image-20240928230842970](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240928230842970.png?token=AVQM64PBKPVLO6AJFSS6TOTHFIXUM)

* 手工操作阶段（无操作系统）：用户独占全机、CPU等待手工操作。

* 单道批处理：系统对作业的处理是成批进行的，但内存中始终保持一道作业。具有**自动性**、**顺序性**、**单道性**。
* 多道批处理：允许多个程序同时进入内存并允许它们在CPU中交替地进行，这些程序共享系统中的各种硬/软件资源。特点是**多道、宏观上并行、微观上串行**。
* **分时操作系统**：分时技术，是指把处理器的运行时间分成很短的**时间片**，按时间片轮流把处理器分配给各联机作业使用。若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时停止运行， 把处理器让给其他作业使用，等待下一轮再继续运行。由于计算机速度很快，作业运行轮转得也很快，因此给每个用户的感觉就像是自己独占一台计算机。分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时与主机进行交互操作而互不干扰。特点是**同时性、交互性、独立性、及时性**。
* 实时操作系统：在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并在严格的时限内处理完接收的事件。实时操作系统的主要特点是**及时性、可靠性**。
  * **硬实时系统**：必须绝对遵守时间限定。
  * **软实时系统**：能偶尔违反时间规定并不会引起永久性损害。
* 网络操作系统：把计算机网络中的各台计算机有机地结合起来，实现各台**计算机之间**数据的互相传送。特点是网络中各种资源的共享及各台计算机之间的通信。 
* **分布式操作系统**：系统中任意两台计算机通过通信方式交换信息；系统中的每台计算机都具有**同等的地位**；每台计算机上的资源为所有用户共享；系统中的任意台计算机都可以构成一个子系统，并且还能重构；任何工作都可以分布在几台计算机上，由它们并行工作、协同完成。特点是**分布性**和**并行性**。分布式操作系统与网络操作系统的本质不同是，分布式操作系统中的若干计算机**相互协同完成同一任务**。
* 个人计算机操作系统：Windows, Linux, MacOS等
* 此外，还有嵌入式操作系统、服务器操作系统、智能手机操作系统等。

## 1.3 操作系统运行环境

* 处理器运行模式：CPU的运行模式分为**用户态**（目态）和**核心态**（管态、内核态）。

  * 核心态：CPU**可以**执行**特权指令**，即出于安全考虑不允许用户直接使用的指令。从核心态切换到用户态的指令也是特权指令。**操作系统内核程序**（管理程序）运行在核心态。注意，核心态也可以执行非特权指令，确切地说，**核心态能执行除了访管指令以外的全部指令**。
  * 用户态：CPU**只能**执行**非特权指令**，即允许用户直接使用的指令，它不能直接访问系统中的软硬件资源，仅限于访问用户的地址空间。**应用程序**（用户自编程序，被管理程序）运行在用户态。应用程序向操作系统请求服务时通过使用**访管指令**（陷入指令），从而产生一个中断事件将操作系统转换为核心态。

* 操作系统的内核：现代操作系统几乎都是分层式结构，操作系统的各项功能分别被设置在不同的层次上。与硬件关联紧密的模块、运行频率较高的程序处于最低层，构成了操作系统的**内核**。内核的指令操作工作在核心态。大多数操作系统的内核包括4方面内容：**时钟管理、中断机制、原语、系统控制的数据结构及处理**。

  * 时钟管理：实现计时、进程切换等功能。
  * 中断机制：只有一小部分功能属于内核。它们负责保护和恢复中断现场的信息，转移控制权到相关的处理程序。这样可以减少中断的处理时间，提高系统的并行处理能力。
  * 原语：原语（Atomic Operation）是一类**程序**。特点为：1. 处于操作系统的最底层，是最接近硬件的部分。2. 运行具有原子性，其操作只能一气呵成（出于系统安全性和便于管理考虑）。3. 运行时间都较短，而且调用频繁。
  * 系统控制的数据结构及处理：系统中用来等级状态信息的数据结构，如作业控制块、进程控制块（PCB）、设备控制块、各类链表、消息队列、缓冲区、空闲区登记表、内存分配表等。系统控制的常见3种操作：**进程管理、存储器管理、设备管理**。

* 中断和异常：用户程序要使用核心态功能，唯一途径就是通过中断和异常。发生中断或异常时，运行用户态的CPU会立即进入核心态，这是通过硬件实现的。

  * **中断**：也称外中断，是指来自CPU执行指令外部的事件，通常用于信息输入/输出，如设备发出的I/O结束中断，表示设备输入/输出处理已经完成。时钟中断，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。外中断可分为可屏蔽中断和不可屏蔽中断。
    * 可屏蔽中断：通过INTR线发出的中断请求，通过改变屏蔽字可以实现多重中断，从而使得中断处理更加灵活。
    * 不可屏蔽中断：通过NMI线发出的中断请求，通常是紧急的硬件故障，如电源掉电等。此外，异常也是不能被屏蔽的。
  * **异常**：也称内中断，是指来自CPU执行指令内部的事件，如程序的非法操作码、地址越界、运算溢出、虚存系统的缺页及专门的陷入指令等引起的事件。异常不能被屏蔽，一旦出现，就应立即处理。异常非为故障、自陷和终止。
    * 故障：由指令执行引起的异常。
    * 自陷：事先安排的“异常”。应用程序的系统调用通过发起访管指令产生访管中断实现，访管中断属于自陷。
    * 终止：出现了使得CPU无法继续执行的硬件故障。
  * 终止异常和外中断属于**硬件中断**，故障异常和自陷异常属于**软件中断**。
  * 中断和异常的处理过程：①执行用户程序的第$i$条指令时检测到异常事件，或执行指令后发现中断请求，则打断当前用户程序，转到相应的中断或异常处理程序去执行；②如果中断或异常处理程序能够解决相应问题，CPU通过执行中断或异常返回指令，回到被打断的用户程序的第$i$条指令或第$i+1$条指令继续执行；③若中断或异常处理程序发现是不可恢复的致命错误，则终止用户程序。 
  * 中断和异常可以发生在用户态，但是中断和异常的**处理**一定发生在内核态。

* 系统调用（广义指令）：指用户在程序中调用操作系统所提供的一些子功能，系统调用可视为特殊的公共子程序。在用户程序中，凡是与资源有关的操作都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

  * 系统调用按功能可以分为：**设备管理、文件管理、进程控制、进程通信、内存管理**。
  * 用户程序通过陷入指令（访管指令）发起系统调用。

* 操作系统的运行环境就可以理解为：用户通过操作系统运行上层程序（如系统提供的命令解释程序或用户自编程序），而这个上层程序的运行依赖于操作系统的底层管理程序提供服务支持，当需要管理程序服务时，系统则通过硬件中断机制进入核心态，运行管理程序；也可能是程序运行出现异常情况，被动地需要管理程序的服务，这时就通过异常处理来进入核心态。管理程序运行结束时，用户程序需要继续运行，此时通过相应的保存的程序现场退出中断处理程序或异常处理程序，返回断点处继续执行。

  **![image-20240929171542320](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240929171542320.png?token=AVQM64KJ3YPNACUY55AJ45THFIXUQ)**

## 1.4 操作系统结构

* 分层法：**按层次划分**将操作系统分为若干层，最低层为硬件层，最高层为用户接口层，每层只能调用**相邻低层**的功能和服务（**单向依赖**）。
  * 优点：①便于系统的调试和验证，简化了系统的设计和实现（单向依赖使得可以从底自上调试）；②易扩充和易维护。
  * 缺点：①合理定义各层比较困难，缺乏灵活性；②效率较差
* 模块化：将操作系统**按功能划分**为若干具有一定独立性的模块。每个模块具有某方面的管理功能，并规定好各模块间的接口，使各模块之间能够通过接口进行通信。还可以进一步将各模块细分为若干具有一定功能的子模块，同样也规定好各子模块之间的接口。这种设计方法被称为**模块-接口法**。
  * **模块的独立性衡量**：理想的情况是**高内聚低耦合**。
    * **内聚性**：模块内部各部分间联系的紧密程度。内聚性越高，模块独立性越好。 
    * **耦合度**：模块间相互联系和相互影响的程度。耦合度越低，模块独立性越好。
  * 优点：①提高了操作系统设计的正确性、可理解性和可维护性；②增强了操作系统的可适应性；③加速了操作系统的开发过程。
  * 缺点：①模块间的接口规定很难满足对接口的实际需求。②各模块设计者齐头并进，每个决定无法建立在上一个己验证的正确决定的基础上，因此无法找到一个可靠的决定顺序。
* 宏内核和微内核：**按操作系统的内核架构划分**，可分为宏内核和微内核。
  * 宏内核：也称单内核或大内核，是指将系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而为用户程序提供高性能的系统服务。因为各管理模块之间共享信息，能有效利用相互之间的有效特性，所以具有无可比拟的性能优势。
    * 目前主流的操作系统，如Windows、Android、iOS、macOS、Linux等，都是**基于**宏内核的构架，但实际上是广泛吸取了微内核构架优点的混合内核。
  * 微内核：微内核架构将内核中最基本的功能保留在内核，而将那些不需要在核心态执行的功能移到用户态执行，从而降低内核的设计复杂性。那些移出内核的操作系统代码根据分层的原则被划分成若干服务程序，它们的执行相互独立，交互则都借助于微内核进行通信。具体地说，当某个进程需要与另一个服务进程通信时，通常需要发送消息。发送消息的过程涉及从用户态进入内核态，调用内核的消息传递机制，再从内核态将消息传递到目标用户态进程。因此每次通信都需要进行2次状态切换。
    * 微内核结构将操作系统划分为两大部分：微内核和多个服务器。微内核是精心设计的、能实现操作系统最基本核心功能的小型内核，通常包含：①与硬件处理紧密相关的部分；②一些较基本的功能；③客户和服务器之间的通信。
    * 只有微内核运行在内核态，其余模块都运行在用户态， 一个模块中的错误只会使这个模块崩溃，不会使整个系统崩溃。
    * 适用于C/S模式、策略与机制分离、分布式系统。
    * **微内核的基本功能**：**进程（线程）管理、低级存储器管理、中断和陷入管理**。
    * **微内核架构的优点**：**扩展性和灵活性、可靠性和安全性、可移植性、分布式计算**。
    * 微内核架构的缺点：需要频繁地在核心态和用户态之间进行切换，操作系统的执行开销偏大。
* 外核：对机器进行分区的机制。外核是一种在内核态中运行的程序，它为虚拟机分配资源，并保持多个虚拟机彼此不发生冲突。每个用户层的虚拟机可以运行自己的操作系统，但限制只能使用已经申请并且获得分配的那部分资源。 
  * 优点：①减少了映射层。在其他的设计中，每个虚拟机都认为它有自己的磁盘，其盘块号从0到最大编号，这样虚拟机监控程序就必须维护一张表格以重映像磁盘地址（或其他资源），有了外核，这个重映射处理就不需要了。外核只需要记录已经分配给各个虚拟机的有关资源即可。②低负载地将多道程序与用户操作系统代码加以分离。

## 1.5 操作系统引导

操作系统引导是指计算机利用CPU运行特定程序，通过程序识别硬盘，识别硬盘分区，识别硬盘分区上的操作系统，最后通过程序启动操作系统，一环扣一环地完成上述过程。

常见的操作系统引导过程：

①激活CPU。激活的CPU读取ROM中的boot程序，将指令寄存器置为BIOS（基本输入/输出系统）的第一条指令，即开始执行BIOS的指令。 

②硬件自检。启动BIOS程序后，先进行硬件自检，检查硬件是否出现故障。如有故障，主板会发出不同含义的蜂鸣，启动中止；如无故障，屏幕会显示CPU、内存、硬盘等信息。 

③加载带有操作系统的硬盘。硬件自检后，BIOS开始读取Boot Sequence （通过CMOS里保存的启动顺序，或者通过与用户交互的方式），把控制权交给启动顺序排在第一位的存储设备， 然后CPU将该存储设备引导扇区的内容加载到内存中。 

④加载主引导记录MBR。硬盘以特定的标识符区分引导硬盘（包含计算机系统启动所需要的引导信息（如主引导记录 MBR 或 GUID 分区表 GPT）以及操作系统的硬盘。）和非引导硬盘。如果发现一个存储设备不是可引导盘，就检查下一个存储设备。如无其他启动设备，就会死机。主引导记录MBR的作用是告诉CPU去硬盘的哪个主分区去找操作系统。 

⑤扫描硬盘分区表，并加载硬盘活动分区。MBR包含硬盘分区表，硬盘分区表以特定的标识符区分活动分区和非活动分区。主引导记录扫描硬盘分区表，进而识别含有操作系统的硬盘分区（活动分区）。找到硬盘活动分区后，开始加载硬盘活动分区，将控制权交给活动分区。 

⑥加载分区引导记录PBR。读取活动分区的第一个扇区，这个扇区称为分区引导记录（PBR）,其作用是寻找并激活分区根目录下用于引导操作系统的程序（启动管理器）。 

⑦加载启动管理器。分区引导记录搜索活动分区中的启动管理器，加载启动管理器。 

⑧加载操作系统。

## 1.6 虚拟机

虚拟机是一台逻辑计算机，是指利用特殊的虚拟化技术，通过隐藏特定计算平台的实际物理特性，为用户提供抽象的、统一的、模拟的计算环境。有两类虚拟化方法：第一类虚拟机管理程序和第二类虚拟机管理程序。

![image-20240929192800389](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240929192800389.png?token=AVQM64IMLZI76M7NQER77NLHFIXUS)

* 第一类虚拟机管理程序：也称为裸金属架构，它在裸机上运行，是唯一一个运行在最高特权级的程序，就像一个操作系统。它向上层提供若干台虚拟机，每台虚拟机都与裸机相同，因此可以运行不同的操作系统。

  * 虚拟机的操作系统运行在**虚拟内核态**，本质上并不是内核态。当虚拟机操作系统执行了一条**敏感指令**（可能影响系统状态和行为的指令，包含特权指令）时，会陷入虚拟机管理程序。

    在支持虚拟化的CPU上，虚拟机管理程序检查这条指令是由虚拟机中的操作系统执行的还是由用户程序执行的。如果是前者，虚拟机管理程序将安排这条指令功能的正确执行。否则，虚拟机管理程序将模拟真实硬件面对用户态执行敏感指令时的行为。

    在不支持虚拟化的CPU上，真实硬件不会直接执行虚拟机中的敏感指令，这些敏感指令被转为对虚拟机管理程序的调用，由虚拟机管理程序模拟这些指令的功能。

* 第二类虚拟机管理程序：也成为寄居架构，它依赖于**宿主操作系统**分配和调度资源的程序，像一个普通的进程，例如VMware。两类虚拟化技术的虚拟机操作系统都称为**客户操作系统**。

# 第 2 章 进程与线程

## 2.1 进程与线程

### 2.1.1 进程

单道程序→多道程序：失去封闭性，并具有了间断性、不可再现性、并发性、共享性。

为了更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性（最基本的两个特性，另外两个特性是虚拟和异步），引入**进程**的概念。

* **进程实体**：也叫**进程映像**，由程序段、相关数据段和**进程控制块（PCB）**三部分构成。PCB是用于管理和跟踪进程信息的数据结构，是*进程存在的唯一标志*。
  * 创建进程实质上是创建进程实体中的PCB，撤销进程同理。
  * 进程映像是**静态**的，进程是**动态**的。
* **进程**：进程是进程实体的**运行过程**，是系统进行资源分配和调度的一个独立单位。
  * 系统资源指设备服务于某个进程的“时间”。例如，处理机资源是处理机的时间片。因为时间片是处理机进行分配和调度的独立单位。
* 进程的特征：进程的基本特征是对比单个程序的顺序执行提出的。它具有动态性、并发性、独立性和异步性。
  * 独立性：指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。
* **进程的状态**：进程有以下5种状态，其中，运行态、就绪态和阻塞态是3种基本状态。
  * **运行态**：每一时刻只有一个进程处于运行态。
  * **就绪态**：进程获得了除处理机外的一切资源。系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。
  * **阻塞态**：又称**等待态**。进程正在等待某一事件（**不包括处理机资源**）而暂停运行，即使处理机空闲，该进程也不能运行。系统通常将处于阻塞态的进程也排成一个队列，甚至根据阻塞原因的不同，设置多个阻塞队列。
  * **创建态**：进程正在被创建，尚未转到就绪态。若进程所需资源尚不能得到满足，则创建工作未完成，进程处于创建态。
  * **终止态**：进程因正常结束或其他原因退出运行而正从系统中消失。进程需要结束运行时，系统首先将该进程置为终止态，然后进一步处理资源释放和回收等工作。
* **进程的状态转换**：进程有5种状态转换，而3种基本状态之间的转换：就绪态→运行态、运行态→就绪态、运行态→阻塞态、阻塞态→就绪态。
  * 进程从运行态变成阻塞态是主动行为，而从阻塞态变成就绪态是被动行为，需要其他相关进程协助。

![image-20240929230710481](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240929230710481.png?token=AVQM64MTP3RDRVR26XI5SUTHFIXUW)

* 进程的组成：**PCB、程序段、数据段**。

  * PCB：系统总是通过PCB对进程进行控制，系统唯有通过进程的PCB才能感知到进程的存在。PCB主要包括进程描述信息、进程控制和管理信息、资源分配清单和处理机相关信息等。
    * 进程描述信息：包括进程标识符（PID）和用户标识符（UID）。
    * 进程控制和管理信息：包括进程当前状态、进程优先级等。
    * 资源分配清单：包括有关内存地址空间或虚拟地址空间的状况（地址指针），所打开文件的列表（文件描述符）和所使用的I/O设备信息。
    * 处理机相关信息：也称处理机上下文，主要指处理机中各寄存器的值。当进程处于执行态时，处理机的许多信息都在寄存器中。当进程被切换时，处理机状态信息都必须保存在相应的PCB中，以便在该进程重新执行时，能从断点继续执行。
    * PCB队列：将各进程的PCB用适当的方法组织起来，对应不同的就绪队列和阻塞队列，以方便进程的调度和管理。常用的组织方式有**链接方式**和**索引方式**，链接方式将同一状态的PCB链接成一个队列，索引方式将同一状态的进程组织在一个索引表中，表项指向相应的PCB。
  * 程序段：能被进程调度程序调度到CPU执行的程序代码段。*多个进程可以运行同一个程序*。
  * 数据段：可以是进程对应的程序加工处理的原始数据，也可以是执行时产生的中间或最终结果。
    * C语言编写的程序在使用内存时一般分为三个段，它们一般是正文段（即代码和赋值数据段）、 数据堆段和数据栈段。二进制代码和常量存放在正文段，动态分配的存储区在数据堆段，临时使用的变量在数据栈段。

* 进程控制：进程控制具有创建新进程、撤销已有进程、实现进程状态转换等功能。一般把进程控制用的程序段称为**原语**，原语的特点是执行期间不允许中断，它是一个不可分割的基本单位。

  * 进程创建：允许一个进程（**父进程**）创建另一个进程（**子进程**）。子进程可以继承父进程拥有的资源，子进程被撤销时，将资源归还给父进程；父进程被撤销时，通常也会同时撤销所有子进程。具体创建过程（**创建原语**）如下：

    1. 为新进程分配唯一PID，并申请一个空白PCB（**PCB是有限的**）。若PCB申请失败则创建失败。
    2. 为进程分配运行所需的资源。若资源不足，则处于创建态等待资源。
    3. 初始化PCB，主要包括标志信息、处理机状态心里、处理机控制信息、进程优先级。
    4. 若就绪队列能够接纳新进程，则插入就绪队列等待被调度运行。

  * 进程终止：引起进程终止的主要有①正常结束；②异常结束，如存储区越界、非法指令、运行超时、I/O故障等；③外界干预，如操作员/操作系统干预、父进程请求/终止。具体终止过程（**终止原语**）如下：

    1. 根据要被终止进程的PID检索PCB，从中读出进程状态。
    2. 若处于运行状态，立即终止进程执行，将**处理机资源**分配给其他进程。
    3. 若进程有子孙进程，终止所有子孙进程。
    4. 将进程拥有的**全部资源**归还给父进程或操作系统。
    5. 将PCB从所在队列中删除。

  * 进程的阻塞和唤醒：正在执行的进程由于期待的某些事件未发生，进程便通过调用**阻塞原语**使自己由运行态变为阻塞态。阻塞是进程的主动行为，只有处于运行态的进程有可能将其转为阻塞态。阻塞原语的执行过程如下：

    1. 根据要被阻塞进程的PID找到对应PCB。
    2. 若该进程为运行态，则保护其现场，将其转为阻塞态，停止运行。
    3. 把该PCB插入阻塞队列，等待调度程序调度。

    当所期待的事件出现时，**相关进程**（例如，释放了该资源的进程）调用唤醒原语，将等待该事件的进程唤醒。唤醒原语的执行过程如下：

    1. 在该事件的等待队列中找到相应进程的PCB。
    2. 将其从等待队列中移出，并置其状态为就绪态。
    3. 把该PCB插入就绪队列，等待调度程序调度。

    阻塞原语和唤醒原语**必须成对使用**，以避免阻塞进程永久处于阻塞状态。

* 进程的通信：即进程之间的信息交换，有低级通信方式和高级通信方式。PV操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式，主要有以下三类：

  * 共享存储：在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程之间的信息交换，如下图左所示。在对共享空间进行写/读操作时，需要使用同步互斥工具（如P操作、V操作），对共享空间的写/读进行控制。共享存储又分为两种：低级方式的共享是基于数据结构的共享；高级方式的共享则是基于存储区的共享。操作系统只负责为通信进程**提供可共享使用的存储空间**（也就是说，共享空间是操作系统新分配的空间）和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。

    注意，进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，想让两个进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是**自然共享进程空间**的。 

    ![image-20240930153643911](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240930153643911.png?token=AVQM64MXM5UHEGWW53Q3223HFIXUY)

  * 消息传递：进程间的数据交换以格式化的**消息**为单位。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。进程通过系统提供的**发送消息和接收消息**两个**原语**进行数据交换。这种方式隐藏了通信实现细节， 使通信过程对用户透明，简化了通信程序的设计，是当前应用**最广泛**的进程间通信机制。在微内核操作系统中，*微内核与服务器之间的通信就采用了消息传递机制*。由于该机制能很好地支持*多处理机系统、分布式系统和计算机网络*，因此也成为这些领域最主要的通信工具。

    * 直接通信：直接通信方式。发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息。
    * 间接通信：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。 这种中间实体一般称为**信箱**。该通信方式广泛应用于计算机网络中。 

  * **管道通信**：允许两个进程按生产者-消费者方式（单方向）进行通信，生产者向管道的一端写，消费者从管道的另一端读。数据在管道中先进先出。只要管道非空，读进程就能读出数据；若数据被读空，则读进程阻塞，直到写进程从管道中写入新的数据。只要管道不满，写进程就能往管道中写入数据，若管道写满，则写进程阻塞，直到读进程读出数据，再将写进程唤醒。为了协调双方的通信，管道机制必须提供三方面的协调能力：互斥、同步和确定对方的存在。 

    * 管道通信在Linux中频繁使用。
    * 管道本质上也是一种文件，但它可以克服使用一般文件进行通信的两个问题：
      1. 限制管道的大小。这使得它的大小不想普通文件那样不加检验地增长。
      2. 读进程可能工作得比写进程快。这种情况下，读进程会被阻塞，等待数据写入，解决了read()调用返回EOF的问题。
    * 管道只能由创建进程访问。父进程创建管道后，子进程会继承父进程的管道（因为管道也是父进程的打开文件），并用其与父进程通信。
    * 普通管道只允许单向通信，双向通信需要定义两个管道。

    ![image-20241105224847841](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241105224847841.png?token=AVQM64PIGKJTH6PA4QRGVA3HFIYI2)

### 2.1.2 线程和多线程模型

引入进程的目的是更好地使多道程序并发执行，提高资源利用率和系统吞吐量；而引入线程的目的则是减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。 

* 线程：线程（Thread）最直接的理解就是“轻量级进程”，它是一个基本的CPU执行单元，也是程序执行流的最小单元，由线程ID、程序计数器、寄存器集合和堆栈组成。

  * 线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。
  * 一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。
  * 线程也有就绪、阻塞和运行三种基本状态。若线程切换发生在同一个进程内部，则时空开销很小。
  * 对比性地说，进程只作为除CPU外的系统资源的分配单元，而线程则作为处理机的分配单元。

* 线程与进程的比较：

  1. **调度**。传统操作系统中，拥有资源和独立调度的基本单位都是进程，每次调度都要进行上下文切换，开销较大。在引入线程的操作系统中，线程是独立调度的基本单位， 而线程切换的代价远低于进程。在同一进程中，线程的切换不会引起进程切换。但从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
  2. **并发性**。在引入线程的操作系统中，不仅进程之间可以并发执行，而且一个进程中的多个线程之间亦可并发执行，甚至不同进程中的线程也能并发执行，从而使操作系统具有更好的并发性，提高了系统资源的利用率和系统的吞吐量。
  3. **拥有资源**。进程是系统中拥有资源的基本单位，而线程不拥有系统资源（仅有一点必不可少、能保证独立运行的资源），但线程可以访问其隶属进程的系统资源，这主要表现在属于同一进程的所有线程都具有相同的地址空间。要知道，若线程也是拥有资源的单位,则切换线程就需要较大的时空开销，线程这个概念的提出就没有意义。
  4. **独立性**。每个进程都拥有独立的地址空间和资源，除了共享全局变量，不允许其他进程访问。某进程中的线程对其他进程不可见。同一进程中的不同线程是为了提高并发性及进行相互之间的合作而创建的，它们共享进程的地址空间和资源。
  5. **系统开销**。在创建或撤销进程时，系统都要为之分配或回收进程控制块PCB及其他资源,如内存空间、I/O设备等。操作系统为此所付出的开销，明显大于创建或撤销线程时的开销。类似地，在进程切换时涉及进程上下文的切换，而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现，甚至无须操作系统的干预。
  6. **支持多处理机系统**。对于传统单线程进程，不管有多少处理机，进程只能运行在一个处理机上。对于多线程进程，可以将进程中的多个线程分配到多个处理机上执行。

* 线程的属性：

  1. 线程是一个轻型实体，它不拥有系统资源，但每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态。
  2. 不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。
  3. 同一进程中的各个线程共享该进程所拥有的资源。
  4. 线程是处理机的独立调度单位，多个线程是可以并发执行的。在单CPU的计算机系统中， 各线程可交替地占用CPU；在多CPU的计算机系统中，各线程可同时占用不同的CPU，若各个CPU同时为一个进程内的各线程服务，则可缩短进程的处理时间。
  5. 一个线程被创建后，便开始了它的生命周期，直至终止。线程在生命周期内会经历阻塞态、就绪态和运行态等各种状态变化。

* 线程的状态与转换：线程在运行时具有3种基本状态，其转换与进程的转换是一样的。

  * 执行状态：线程已获得处理机而正在运行。
  * 就绪状态：已具备除了CPU外的所有执行条件。
  * 阻塞状态：执行中因某事件受阻而处于暂停状态。

* 线程的组织与控制：

  * **线程控制块（TCB）**：通常包括：①线程标识符；②一组寄存器，包括程序计数器、状态寄存器和通用寄存器；③线程运行状态，用于描述线程正处于何种状态；④优先级；⑤线程专有存储区，线程切换时用于保存现场等；⑥堆栈指针，用于过程调用时保存局部变量及返回地址等。
    * 同一进程中的所有线程都完全共享进程的地址空间和全局变量。各个线程都可以访问进程地址空间的每个单元，所以一个线程可以读、写或甚至清除另一个线程的堆栈。
  * 线程的创建：线程由创建而产生，由调度而执行，由终止而消亡。相应地，在操作系统中就有用于创建线程和终止线程的**函数**(或**系统调用**)。程序启动时，通常仅有一个“初始化线程”正在执行，它用于创建新线程。创建新线程时，需要利用线程创建函数并提供相应参数，函数执行完后将返回一个TID。
  * 线程的终止：线程完成任务后或运行中出现异常而要被强制终止时，由终止线程（线程本身或上下文线程，不是一个特定概念）调用相应的函数执行终止操作。但是有些线程（主要是系统线程）一旦被建立，便一直运行而不会被终止。通常，线程被终止后并不立即释放它所占有的资源，只有当进程中的其他线程执行了**分离函数**后，被终止线程才与资源分离，此时的资源才能被其他线程利用。 被终止但尚未释放资源的线程仍可被其他线程调用，以使被终止线程重新恢复运行。

* 线程的实现方式：可以分为**用户及线程（ULT）**和**内核级线程**（**KLT**，又称为**内核支持的线程**）。

  * ULT：有关线程管理(创建、撤销和切换等)的所有工作都由应用程序在**用户空间**中完成，**内核意识不到线程的存在**。应用程序可以通过使用线程库设计成多线程程序。通常， 应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。
    * ULT的调度仍以进程为单位，因此包含不同数量ULT的进程会分到相同数量的时间片，ULT越多其运行时间越短，因此对线程而言是不公平的。
    * 优点：①线程切换不需要转换到内核空间，节省了模式切换的开销。②调度算法可以是进程专用的，不同的进程可根据自身的需要，对自己的线程选择不同的调度算法。 ③用户级线程的实现与操作系统平台无关，对线程管理的代码是属于用户程序的一部分。
    * 缺点：①系统调用的阻塞问题，当线程执行一个系统调用时，不仅该线程被阻塞，而且进程内的**所有线程都被阻塞**。②不能发挥多处理机的优势，内核每次分配给一个进程的仅有一个CPU，因此进程中仅有一个线程能执行。
  * KLT：内核级线程在内核的支持下运行，线程管理的所有工作也是在内核空间内实现的。内核空间为每个内核级线程设置一个线程控制块，内核根据该控制块感知某线程的存在，并对其加以控制。
    * 优点：①能发挥多处理机的优势，内核能同时调度同一进程中的多个线程并行执行。②如果进程中的一个线程被阻塞，内核可以调度该进程中的其他线程占用处理机， 也可运行其他进程中的线程。③内核支持线程具有很小的数据结构和堆栈，线程切换比较快、开销小。④内核本身也可采用多线程技术，可以提高系统的执行速度和效率。 
    * 缺点：同一进程中的线程切换，需要从用户态转到核心态进行，系统开销较大。这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的。
  * 组合方式：一些内核级线程对应多个用户级线程，这是用户级线程通过**时分多路复用内核级线程**实现的。同一进程中的多个线程可以同时在多处理机上并行执行，且在阻塞一个线程时不需要将整个进程阻塞，所以组合方式能结合KLT和ULT的优点，并且克服各自的不足。
  * 线程库：为程序员提供创建和管理线程的API。前面提到，线程的创建有函数和系统调用两种方式，分别对应了两种线程库的主要实现方法，用户级线程库和内核级线程库。目前使用的三种主要线程库是：POSIX Pthreads（两者皆可）、Windows API（内核级）、Java API（用户级）。因此，Java线程要实现内核级线程，通常在Windows系统中采用Windows API，在类UNIX系统中采用Pthreads。

  ![image-20240930181107707](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240930181107707.png?token=AVQM64ONQW66UKFBVW7CCTTHFIXU4)

* 多线程模型：根据线程的实现方式，用户级线程和内核级线程连接方式有所不同，从而形成了三种多线程模型。
  * 多对一模型（用户级方式）。这些用户线程一般属于一个进程，线程的调度和管理在用户空间完成。仅当用户线程需要访问内核时， 才将其映射到一个内核级线程上，但是每次只允许一个线程进行映射。 
    * 优点：线程管理是在用户空间进行的，因而效率比较高。 
    * 缺点：如果一个线程在访问内核时发生阻塞，则整个进程都会被阻塞；在任何时刻，只有一个线程能够访问内核，多个线程不能同时在多个处理机上运行。
  * 一对一模型（内核级方式）。
    * 优点：当一个线程被阻塞后，允许调度另一个线程运行，所以并发能力较强。 
    * 缺点：每创建一个用户线程，相应地就需要创建一个内核线程，开销较大。
  * 多对多模型（组合方式）。将$n$个用户线程映射到$m$个内核级线程上，$n\geq m$。
    * 特点：既克服了多对一模型并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程而开销太大的缺点。此外，还拥有上述两种模型各自的优点。

## 2.2 处理机调度

### 2.2.1 调度的概念和目标

* 调度：处理机调度是对处理机进行分配，即从就绪队列中按照一定的**算法**选择一个进程并将处理机分配给它运行，以实现进程并发地执行。

* 调度的层次：一个作业从提交开始直到完成，往往要经历三级调度。

  * **高级调度（作业调度）**：按照一定的原则从**外存**上处于后备队列的作业中挑选一个（或多个），给它（们）分配内存、 输入/输出设备等必要的资源，并建立相应的进程，以使它（们）获得竞争处理机的权利。简言之，作业调度就是**内存与辅存之间的调度**。每个作业只调入一次、调出一次。除多道批处理系统外，其他系统通常不需要配置作业调度。

  * **中级调度（内存调度）**：引入中级调度的目的是提高内存利用率和系统吞吐量。为此，将那些暂时不能运行的进程调至**外存**等待，此时进程的状态称为**挂起态**。当它们己具备运行条件且内存又稍有空闲时，由中级调度来决定把外存上的那些己具备运行条件的就绪进程再**重新调入内存**，并修改其状态为**就绪态**，挂在就绪队列上等待。中级调度实际上是存储器管理中的对换功能。

  * **低级调度（进程调度）**：按照某种算法从就绪队列中选取一个进程，将处理机分配给它。进程调度是最基本的一种调度，在各种操作系统中都必须配置这级调度。进程调度的频率很高，一般几十毫秒一次。（注意，这是经典的调度层次，事实上现在的低级调度还会包括线程调度）

    ![image-20240930213015747](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240930213015747.png?token=AVQM64PWUXXESNFW4OWU4JDHFIXVA)

* 三级调度的联系：

  * 作业调度为进程活动做准备，进程调度使进程正常活动起来。
  * 中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。
  * 作业调度次数少，中级调度次数略多，进程调度频率最高。
  * 进程调度是最基本的，不可或缺。

* 调度的目标：不同的调度算法又不同特性，在选择调度算法时，必须要考虑算法的特性与调度目标是否匹配。设计调度程序，一方面要满足特定系统用户的要求（如某些实时和交互进程的快速响应要求），另一方面要考虑系统整体效率（如减少整个系统的进程平均周转时间），同时还要考虑调度算法的开销。主要的调度目标有以下几种。

  * **CPU利用率**：
    $$
    \text{CPU利用率}=\frac{\text{CPU有效工作时间}}{\text{CPU有效工作时间}+CPU空闲等待时间}
    $$

  * **系统吞吐量**：单位时间内CPU完成作业的数量。显然，短作业能提高系统吞吐量。

  * **周转时间**：从作业提交到作业完成所经历的时间。
    $$
    \begin{align}
    \text{周转时间}&=\text{作业完成时间}-\text{作业提交时间}\\
    &=\text{作业等待时间}+\text{就绪队列排队时间}+\text{处理机上运行及I/O时间}\\
    带权周转时间&=\frac{作业周转时间}{作业实际运行时间}
    \end{align}
    $$

  * **等待时间**：进程处于等处理机的时间之和。处理机调度算法实际上并不影响作业执行或输入/输出操作的时间，只影响作业在就绪队列中等待所花的时间。因此，衡量一个调度算法的优劣，常常只需简单地考察等待时间。（这里的等待时间等于周转时间公式中的作业等待时间+排队时间）

  * **响应时间**：从用户提交请求到系统首次产生响应所用的时间。在交互式系统中，周转时间不是最好的评价准则，一般采用响应时间作为衡量调度算法的重要准则之一。从用户角度来看，调度策略应尽量降低响应时间，使响应时间处在用户能接受的范围之内。

### 2.2.2 调度的实现

* 调度程序（调度器）：用于调度和分派CPU的组件，通常由三部分组成：**排队器、分派器、上下文切换器**。

  ![image-20240930222949710](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20240930222949710.png?token=AVQM64LT6VTT75LHAOT56CDHFIXVE)

  * **排队器**：将系统中的所有就绪进程按照一定的策略排成一个或多个队列，以便于调度程序选择。每当有一个进程转变为就绪态时，排队器便将它插入到相应的就绪队列中。

  * **分派器**：依据调度程序所选的进程，将其从就绪队列中取出，将CPU分配给新进程。

  * **上下文切换器**：在对处理机进行切换时，会发生两对上下文的切换操作：第一对，将**当前进程的上下文**保存到其PCB中，再装入**分派程序的上下文**，以便分派程序运行；第二对，移出**分派程序的上下文**，将**新选进程的CPU现场信息**装入处理机的各个相应寄存器。 

    在上下文切换时，需要执行大量load和store指令，以保存寄存器的内容，因此会花费较多时间。现在已有硬件实现的方法来减少上下文切换时间。通常采用两组寄存器，其中一组供内核使用，一组供用户使用。这样，上下文切换时，只需改变指针，让其指向当前寄存器组即可。

* 调度的时机、切换与过程：理论顺序：请求调度→运行调度程序→进程切换。但在实际的操作系统内核程序运行中，若某时刻发生了引起进程调度的因素，则不一定能马上进行调度与切换。 

  不能进行进程调度与切换的情况：

  1. 在处理中断的过程中。
  2. 进程在操作系统内核临界区。
  3. 其他需要完全屏蔽中断的原子操作的过程中。

  若在上述过程中发生了引起调度的条件，则不能马上进行调度和切换，应置系统的请求调度标志，直到上述过程结束后才进行相应的调度与切换。

  应该进行进程调度与切换的情况：

  1. 发生引起调度条件且当前进程无法继续运行下去时。
  2. 中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换。若操作系统支持这种情况下的运行调度程序，则实现了**剥夺方式**的调度。

* **进程调度方式**：指当某个进程正在处理机上执行时，若有某个有优先权更高的进程进入就绪队列，此时应如何分配处理机。 

  * **非抢占调度方式**：又称**非剥夺方式**。是指当一个进程正在处理机上执行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在执行的进程继续执行，直到该进程运行完成或发生某种事件而进入阻塞态时，才把处理机分配给其他进程。 
    * 优点：实现简单、系统开销小，适用于大多数的批处理系统。
    * 缺点：不能用于分时系统和大多数实时系统。

  * **抢占调度方式**：又称**剥夺方式**。是指当一个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要使用处理机，则允许调度程序**根据某种原则**（主要有优先权、短进程优先和时间片原则等）去暂停正在执行的进程， 将处理机分配给这个更为重要或紧迫的进程。 
    * 优点：提高系统吞吐率和响应效率。

* 闲逛进程：在进程切换时，如果系统中没有就绪进程，就会调度**闲逛进程**（idle）运行，如果没有其他进程就绪，该进程就一直运行，并在执行过程中测试中断。闲逛进程的**优先级最低**，没有就绪进程时才会运行闲逛进程，只要有进程就绪，就会立即让出处理机。 *闲逛进程不需要CPU之外的资源，它不会被阻塞*。

* **线程调度**：
  * **用户级线程调度**：由于内核并不知道线程的存在，所以内核还是和以前一样，选择一个进程，并给予时间控制。*由进程中的调度程序决定哪个线程运行。*
  * **内核级线程调度**：内核选择一个特定线程运行，通常*不用考虑该线程属于哪个进程*。对被选择的线程赋予一个时间片，如果超过了时间片，就会强制挂起该线程。 
  * 比较：用户级线程的线程切换在同一进程中进行，仅需少量的机器指令；内核级线程的线程切换需要完整的上下文切换、修改内存映像、使高速缓存失效，这就导致了若干数量级的延迟。

### 2.2.3 典型调度算法

操作系统中存在多种调度算法，有的调度算法适用于作业调度，有的调度算法适用于进程调度，有的调度算法两者都适用。

* **先来先服务（FCFS）调度算法**：适用于作业调度和进程调度。FCFS调度算法属于**不可剥夺算法**。

  * 进程调度：每次从就绪队列中选择最先进入该队列的进程，将处理机分配给它，使之投入运行，直到运行完成或因某种原因而阻塞时才释放处理机。
  * 作业调度：每次从后备作业队列中选择最先进入该队列的**一个或几个作业**（后同，不再赘述），将它们调入内存，分配必要的资源，创建进程并放入就绪队列。 
  * 特点：算法简单，但效率低；对长作业比较有利，但对短作业不利（相对SJF和高响应比）；**有利于CPU繁忙型作业，而不利于I/O繁忙型作业**。不能作为分时系统和实时系统的主要调度策略，但常被结合在其他调度策略中使用。

  ![image-20241002153643166](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002153643166.png?token=AVQM64MEY475ZC56ALWVT5DHFIXVI)

* **短作业优先（SJF）调度算法**：适用于作业调度（SJF）和进程调度（此时称为**短进程优先**，SPF）。“短”指的是运行时间，但前提是该作业已经被提交至系统。

  ![image-20241002154349751](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002154349751.png?token=AVQM64PXDJMCFJD2FJ25QBLHFIXVM)

  * 优点：**平均等待时间、平均周转时间最少**。
  * 缺点：
    1. 对长作业不利。长作业的周转时间会增加，且长作业可能长期不被调度（**“饥饿”现象**）。
    2. 没有考虑作业的紧迫成都，不能保证紧迫作业被及时处理。
    3. 作业的长短是根据用户的估计执行时间而定，用户可能会有意或无意地缩短估计，导致不一定真正做到短作业优先。

* **优先级调度算法**：适用于作业调度和进程调度。使用优先级描述作业的紧迫程度。

  * 根据新的更高优先级进程能否抢占正在执行的进程，分为**非抢占式**和**抢占式**。
    * 例：抢占式SPF：每当有新进程到达时，比较所有进程的**剩余运行时间**，若当前运行的进程剩余时间最短，继续执行；否则选取剩余时间最短的进程运行，直到下一个新进程到达或该进程完成，重复该过程。
  * 根据进程创建后其优先级是否可以改变，分为**静态优先级**和**动态优先级**。
    * 静态优先级：主要依据有进程类型、进程对资源的要求、用户要求。
    * 动态优先级：主要依据有进程占有CPU时间长短、就绪进程等待CPU时间长短。
  * 进程优先级的设置原则：
    1. 系统进程>用户进程。
    2. 交互型进程>非交互型进程（前台进程>后台进程）。
    3. I/O型进程>计算型进程。I/O型进程指会频繁使用I/O设备的进程，而计算型进程是那些频繁使用CPU的进程（很少使用I/O设备）。I/O设备（如打印机）的处理速度要比CPU慢得多，因此若将I/O型进程的优先级设置得更高，就更有可能让I/O设备尽早开始工作，进而提升系统的整体效率。

* **高响应比优先（HRRN）调度算法**：主要用于作业调度。同时考虑了每个作业的等待时间和估计的运行时间，综合平衡了FCFS和SJF。每次作业调度时对后备作业队列中的每个作业计算一次响应比，选择响应比最高的作业投入运行。
  $$
  响应比R_p=\frac{等待时间+要求服务时间}{要求服务时间}
  $$
  根据公式可知：①作业的等待时间相同时，要求服务时间越短，响应比越高，有利于短作业，因而类似于SJF。②要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而类似于FCFS。③对于长作业，作业的响应比可以随等待时间的增加而提高， 当其等待时间足够长时，也可获得处理机，克服了“饥饿”现象。

* **时间片轮转调度算法**：主要适用于分时系统的进程调度。系统将所有就绪进程按**FCFS策略**排成一个就绪队列，调度程序总是选择就绪队列中的第一个进程执行，但仅能运行一个时间片。在使用完一个时间片后，即使进程并未运行完成，它也必须释放出（**被剥夺**）处理机给下一个就绪进程，而被剥夺的进程返回到就绪队列的末尾**重新排队**，等候再次运行。 

  * 时间片的大小选择对系统性能至关重要。时间片过大则退化为FCFS，时间片过小则频繁切换进程导致处理机开销增大，真正用于运行用户进程的时间减少。时间片的长短选择通常考虑：系统的响应时间、就绪队列中的进程数目、系统的处理能力。

* **多级队列调度算法**：适用于作业调度和进程调度。在系统中设置多个就绪队列，将不同类型或性质的进程固定分配到不同的就绪队列。 每个队列可实施不同的调度算法，因此，系统针对不同用户进程的需求，很容易提供多种调度策略。同一队列中的进程可以设置不同的优先级，不同的队列本身也可以设置不同的优先级。

* **多级反馈队列调度算法（融合）**：主要适用于进程调度。时间片轮转调度算法和优先级调度算法的综合与发展，通过动态调整进程优先级和时间片大小兼顾多方面的系统目标。实现思想如下（只是一个例子，实际上各并非必须采用FCFS或示意的进程迁移方式）：

  1. 设置多个就绪队列，并为每个队列赋予不同的优先级。
  2. 赋予各个队列的进程运行时间片的大小各不相同。*在优先级越高的队列中，每个进程的时间片就越小*。
  3. 每个队列都采用FCFS算法。当新进程进入内存后，首先将它放入第1级队列的末尾，按FCFS原则等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可撤离系统。 若它在一个时间片结束时尚未完成，调度程序将其转入第2级队列的末尾等待调度，以此类推。当进程被降到最低级后，则采用时间片轮转方式运行。
  4. 按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运行；仅当第1~$i-1$级队列均为空时，才会调度第$i$​级队列中的进程运行。若处理机正在执行第$i$级队列中的某进程时，又有新进程进入任何一个优先级较高的队列，此时须立即把正在运行的进程放回到第$i$级队列的**末尾**，而把处理机分配给新到的高优先级进程。

  * 优点：
    * 终端型作业用户：短作业优先
    * 短批处理作业用户：周转时间较短
    * 长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理。

![image-20241002164152666](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002164152666.png?token=AVQM64OUKOE6KAGWJI3FRELHFIXVO)

### 2.2.4 进程切换

对于通常的进程而言，其创建、撤销及要求由系统设备完成的I/O操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的， 因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

* **上下文切换**：切换CPU到另一个进程需要保存当前进程状态并恢复另一个进程的状态，这个任务称为上下文切换。上下文是指某一时刻CPU**寄存器和程序计数器**的内容。进行上下文切换时，内核会将旧进程状态保存在其PCB中，然后加载经调度而要执行的新进程的上下文。

  上下文切换实质上是指处理机从一个进程的运行转到另一个进程上运行，在这个过程中，进程的运行环境产生了实质性的变化。上下文切换的流程如下：

  1. 挂起一个进程，保存CPU上下文。
  2. 更新PCB信息。
  3. 把进程的PCB移入相应的队列。
  4. 选择另一个进程执行，并更新其PCB。
  5. 跳转到新进程PCB中的程序计数器所指向的位置执行。
  6. 恢复处理机上下文。

* 上下文切换的消耗：上下文切换通常是计算密集型的，即它需要相当可观的CPU时间。有些处理器提供多个寄存器组，这样，上下文切换就只需要简单改变当前寄存器组的指针。

* 上下文切换与模式切换：模式切换与上下文切换是不同的，模式切换时，CPU逻辑上可能还在执行同一进程。用户态和内核态之间的切换称为模式切换，而不是上下文切换，因为没有改变当前的进程。上下文切换只能发生在内核态，它是多任务操作系统中的一个必需的特性。

## 2.3 同步与互斥

### 2.3.1 基本概念

在多道程序的环境下，进程是并发、异步的。但有些进程的先后顺序是不可交换的，例如计算1+2×3时的加法进程和乘法进程。因此要制定一定的机制去约束进程的发生顺序。

* **临界资源**：一次仅允许一个进程使用的资源。许多物理设备都属于临界资源，如打印机等。 还有许多变量、数据等都可以被若干进程共享，也属于临界资源。

  对临界资源的访问，必须互斥地进行，在每个进程中，访问临界资源的那段**代码**称为**临界区**（Critical Section, 国外习惯称为Critical Code Block）。 为了保证临界资源的正确使用，可把临界资源的访问过程分成4个部分：

  1. **进入区**。在进入区要检查可否进入临界区，若能进入临界区，则应设置正在访问临界区的标志，以阻止其他进程同时进入临界区。
  2. **临界区**。进程中访问临界资源的那段代码，又称**临界段**。
  3. **退出区**。将正在访问临界区的标志清除。
  4. **剩余区**。代码的剩余部分。

* **同步**：亦称直接制约关系。为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系源于它们之间的相互**合作**。

  例如，输入进程A通过单缓冲向进程B提供数据。当该缓冲区空时，进程B不能获得所需数据而阻塞，一旦进程A将数据送入缓冲区，进程B就被唤醒。反之，当缓冲区满时，进程A被阻塞，仅当进程B取走缓冲数据时，才唤醒进程A。

  为禁止两个进程同时进入临界区，同步机制应遵循以下准则：

  1. **空闲让进**。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。
  2. **忙则等待**。当己有进程进入临界区时，其他试图进入临界区的进程必须等待。
  3. **有限等待**。对请求访问的进程，应保证能在有限时间内进入临界区。
  4. **让权等待**。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。

  对于互斥机制，必须遵守前3个准则，让权等待是非必须满足的。

* **互斥**：互斥也称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。

  例如，在仅有一台打印机的系统中，有两个进程A和进程B，若进程A需要打印时，系统己将打印机分配给进程B,则进程A必须阻塞。一旦进程B将打印机释放，系统便将进程A唤醒，并将其由阻塞态变为就绪态。

  也就是说，同步是合作关系，互斥是**竞争**关系。

### 2.3.2 临界区互斥的基本实现方法

本节内容只需理解，不需要记忆具体实现，因为计算机内部实现并非使用的这些代码，本节的代码只是为了表述实现过程。

1. **软件实现方法**

   在进入区设置并检查一些标志来标明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。

   * **单标志法**：设置一个公用整型变量`turn`，用于指示被允许进入临界区的进程编号。

     * 缺点：两个进程必须交替进入临界区，若某个进程不再进入临界区，则另一个进程也将无法进入临界区（违背"空闲让进”）。这样很容易造成资源利用不充分。

     ![image-20241002193116093](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002193116093.png?token=AVQM64NVQADL6X54TMXYXZDHFIXVS)

   * **双标志法先检查**：在每个进程访问临界区资源之前，先查看临界资源是否正被访问，若正被访问，该进程需等待；否则，进程才进入自己的临界区。为此，设置一个布尔型数组`flag[]`，如第$i$个元素`flag[i]`为`FALSE`，表示$P_i$进程未进入临界区，如为`TRUE`，表示$P_i$进程进入临界区。

     * 优点：不用交替进入，可连续使用。
     * 缺点：在检查对方的flag后和切换自己的flag前有一段时间，结果都检查通过，导致$P_i$和$P_j$同时进入临界区（违背“忙则等待”）。问题出在检查和修改操作不能一次进行。

     ![image-20241002205046319](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002205046319.png?token=AVQM64IQYQ63RVLJACRXDP3HFIXVW)

   * **双标志法后检查**：先将自己的标志设置为`TRUE`，再检测对方的状态标志， 若对方标志为`TRUE`，则进程等待； 否则进入临界区。

     * 缺点：两个进程几乎同时都想进入临界区时，它们分别将自己的标志值flag设置为`TRUE`，并且同时检测对方的状态，发现对方也要进入临界区时，双方互相谦让， 结果谁也进不了临界区，从而导致**“饥饿”现象**。

     ![image-20241002205440256](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002205440256.png?token=AVQM64IFVU3XGDNRRVZT243HFIXV2)

   * **Peterson's Algorithm**：为了防止两个进程为进入临界区而无限期等待，又设置了变量`turn`，每个进程在先设置自己的标志后再设置turn标志。这时，再同时检测另一个进程状态标志和允许进入标志，以便保证两个进程同时要求进入临界区时，只允许一个进程进入临界区。

     换句话说，单标志法是“能不能进”，双标志后检查法是“想不想进”，Peterson算法是“想进且能进/不想进或不能进”。

2. **硬件实现方法**

   计算机提供了特殊的硬件指令， 允许对一个字中的内容进行检测和修正，或对两个字的内容进行交换等。通过硬件支持实现临界段问题的方法称为**低级方法**，或称**元方法**。

   * **中断屏蔽方法**：当一个进程正在执行它的临界区代码时，防止其他进程进入其临界区的最简方法是**关中断**。因为CPU只在发生中断时引起进程切换，因此屏蔽中断能够保证当前运行的进程让临界区代码顺利地执行完，进而保证互斥的正确实现，然后执行开中断。

     * 缺点：限制了处理机交替执行程序的能力，执行效率会明显降低。将关中断的权利交给用户是不明智的选择，可能因为进程关中断后不再开中断导致系统终止。

     ![image-20241002211145517](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002211145517.png?token=AVQM64LSRULB4Y3NPHG2L33HFIXV4)

   * **硬件指令方法**：

     **`TestAndSet`指令**：这条指令是原子操作，即执行该代码时**不允许被中断**。其功能是读出指定标志后把该标志设置为真。

     可以为每个临界资源设置一个共享布尔变量`lock`，表示资源的两种状态：`true`表示正被占用， 初值为`false`。进程在进入临界区之前，利用`TestAndSet`检查标志`lock`，若无进程在临界区，则其值为`fhlse`，可以进入，关闭临界资源，把`lock`置为`true`，使任何进程都不能进入临界区；若有进程在临界区，则循环检查，直到进程退出。利用该指令实现互斥的过程描述如下： 

     ![image-20241002211925981](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002211925981.png?token=AVQM64KEDA4B5M6X7BL5Q7LHFIXWA)

     **`Swap`指令**：该指令同样是原子操作，其功能是交换两个字（字节）的内容。

     为每个临界资源设置一个共享布尔变量`lock`，初值为`false`；在每个进程中再设置一个局部布尔变量`key`，用于与`lock`交换信息。在进入临界区前， 先利用`Swap`指令交换`lock`与`key`的内容，然后检查`key`的状态；有进程在临界区时，重复交换和检查过程，直到进程退出。其处理过程描述如下：

     ![image-20241002212637238](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002212637238.png?token=AVQM64MKZ3KGMENL47PE7MDHFIXWC)

     * 优点：适用于任意数目的进程，而不管是单处理机还是多处理机；简单、容易验证其正确性。可以支持进程内有多个临界区，只需为每个临界区设立一个布尔变量。 
     * 缺点：进程等待进入临界区时要耗费处理机时间，不能实现让权等待。从等待进程中随机选择一个进入临界区，有的进程可能一直选不上，从而导致"饥饿”现象。

### 2.3.3 互斥锁

解决临界区最简单的工具就是**互斥锁**（mutex lock）。一个进程在进入临界区时应获得锁；在退出临界区时释放锁。函数`acquire()`获得锁，而函数`release()`释放锁。 每个互斥锁有一个布尔变量`available`，表示锁是否可用。如果锁是可用的，调用`acquire()`会成功，且锁不再可用。当一个进程试图获取不可用的锁时，会被阻塞，直到锁被释放。

`acquire()`和`release()`的执行必须是原子操作，因此互斥锁通常采用硬件机制实现。

互斥锁的主要特点是**忙等待**，当有一个进程在临界区中，任何其他进程在进入临界区时必须**连续循环调用**`acquire()`。当多个进程共享同一个CPU时，就浪费了CPU周期。因此，互斥锁通常用于多处理器系统，一个线程可以在一个处理器上等待，不影响其他线程的执行。 

### 2.3.4 信号量

信号量机制是一种功能较强的机制，可用来解决互斥与同步问题，它只能被两个标准的**原语**`wait(S)`和`signal(S)`访问，也可记为**“P操作”**和**"V操作**”。 

原语是指完成某种功能且不被分割、不被中断执行的操作序列，通常可由硬件来实现。例如，前述的`TestAndSet`和`Swap`指令就是由硬件实现的原子操作。原语功能的不被中断执行特性在单处理机上可由软件通过屏蔽中断方法实现。原语之所以不能被中断执行，是因为原语对变量的操作过程若被打断，可能会去运行另一个对同一变量的操作过程，从而出现临界段问题。

1. **整型信号量**

   整型信号量被定义为一个用于表示**资源数目**的整型量S。

   * P操作：若S>0，减1表示请求一个资源，否则阻塞（不断测试S）。
   * V操作：S加1，表示释放一个资源。

   在整型信号量机制中的wait操作，只要信号量S≤0，就会不断地测试。因此，该机制并未遵循“让权等待”的准则，而是使进程处于“**忙等**”的状态。

2. **记录型信号量**

   记录型信号量是一种不存在“忙等”现象的进程同步机制。除了需要一个用于代表资源数目的整型变量`value`外，再增加一个**进程链表**`L`，用于链接所有等待该资源的进程。记录型信号量得名于采用了记录型的数据结构。记录型信号量可描述为

   ![image-20241002220443781](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002220443781.png?token=AVQM64OH4XOO3SMZSFYZH7DHFIXWE)

   * P操作：`value`减1，随后若`value`<0，进程调用`block`原语自我阻塞，放弃处理机，并插入该类资源的等待队列。
   * V操作：`value`加1，随后若`value`仍≤0，则表示仍有等待该资源的进程被阻塞（数量等于`value`的绝对值），因此要调用`wakeup`原语，将等待队列的第一个进程唤醒。

3. 利用信号量实现同步

   设$S$为实现进程$P_1, P_2$同步的公共信号量， 初值为0。进程$P_2$中的语句y要使用进程$P_1$中语句x的运行结果，所以只有当语句x执行完成之后语句y才可以执行。其实现进程同步的算法如下：

   ![image-20241002222029709](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002222029709.png?token=AVQM64JLX66O56JVA3IYAZTHFIXWI)

4. 利用信号量实现进程互斥

   设$S$为实现进程$P_1, P_2$互斥的信号量，由于每次只允许一个进程进入临界区，所以$S$的初值应为1（即可用资源数为1）。只需把临界区置于P(S)和V(S)之间，即可实现两个进程对临界资源的互斥访问。其算法如下：

   ![image-20241002222306343](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241002222306343.png?token=AVQM64MXY3KD3QJQ6IYVYSDHFIXWM)

5. 利用信号量实现前驱关系

   信号量也可用来描述程序之间或语句之间的前驱关系。下图中，$S_1,S_2,S_3,\cdots,S_6$是最简单的程序段（只有一条语句）。为使各程序段能正确执行，应设置若干初始值为"0"的信号量。例如，为保证$S_1\rightarrow S_2,S_2\rightarrow S_3$的前驱关系，应分别设置信号量$a_1,a_2$。

   ![image-20241003144811158](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003144811158.png?token=AVQM64PSWAHR2PQZFPEDMLDHFIXWQ)

   ![image-20241003145025918](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003145025918.png?token=AVQM64NMI2JDY4ASQDMBJITHFIXWU)

### 2.3.5 管程

在信号量机制中，每个要访问临界资源的进程都必须自备同步的PV操作，大量分散的同步操作给系统管理带来了麻烦，且*容易因同步操作不当而导致系统死锁*。于是，便产生了一种新的进程同步工具一一**管程（monitor）**。管程的特性保证了进程互斥，无须程序员自己实现互斥，从而降低了死锁发生的可能性。同时管程提供了条件变量，可以让程序员灵活地实现进程同步。

* 定义：代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，称为管程（monitor）。管程定义了一个**数据结构**和能为并发进程所执行（在该数据结构上）的一组**操作**，这组操作能同步进程和改变管程中的数据。 

  * 管程由4部分组成：

    1. 管程的**名称**；
    2. 共享**数据结构**说明；
    3. 对该数据结构进行操作的一组**过程**（或**函数**）；
    4. 对共享数据设置**初始值**的语句。

    管程的组成很像一个**类**。每次仅允许一个进程进入管程，从而实现进程互斥。若多个进程同时调用，则只有某个进程运行完它调用的过程后，下个进程才能开始运行它调用的过程，即各个进程**只能串行执行**管程内的过程。

* 条件变量：当一个进程进入管程后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放管程， 那么其他进程无法进入管程。为此，将阻塞原因定义为**条件变量condition**。管程中可以有多个条件变量，每个条件变量保存了一个**等待队列**， 用于记录因该条件变量而阻塞的所有进程，对条件变量只能有`wait`和`signal`两种操作。
  * `x.wait()`：当x对应的条件不满足时，正在调用管程的进程调用`x.wait`将自己插入x条件的等待队列，并释放管程。此时其他进程可以使用该管程。
  * `x.signal()`：x对应的条件发生了变化，则调用`x.signal`，唤醒一个因x条件而阻塞的进程。 
* 条件变量和信号量的异同：
  * 同：`wait`和`signal`操作，类似于信号量的P/V操作，可以实现进程的阻塞和唤醒。
  * 异：条件变量**没有值**，仅实现了“排队等待”功能，剩余资源数由管程的共享数据结构记录。信号量是有值的。

### 2.3.6 经典同步问题

1. **生产者-消费者问题**

   * 问题描述：一组生产者进程和一组消费者进程共享一个初始为空、大小为$n$的缓冲区，只有缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待；只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源；它只允许一个生产者放入消息，或一个消费者从中取出消息。

   * 分析：生产者和消费者对缓冲区的访问是互斥关系，但同时两者之间又存在同步关系。因此，为缓冲区设置一个互斥信号量`mutex`；为生产者的访问设置“空”缓冲区数`empty`，初始化为n，相当于生产者的可用资源数；为消费者的访问设置“满”缓冲区数`full`，初始化为0，相当于消费者的可用资源数。

     ![image-20241003153812558](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003153812558.png?token=AVQM64K3WI55ZA6IPXEIFW3HFIXW2)

     注意，不能先获取互斥锁，再对`empty/full`进行P操作。因为，假设生产者先获取了互斥锁再进行P操作，当可用资源不足时，进程将被阻塞，互斥锁无法被释放。此时，消费者若再请求互斥锁，就会**形成死锁**。反之同理。但`mutex`和`full/empty`的释放没有先后要求。

   * 更复杂的生产者消费者问题：桌子上有一个盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等吃盘子中的橘子，女儿专等吃盘子中的苹果。只有盘子为空时， 爸爸或妈妈才可向盘子中放一个水果；仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出。

   * 分析：爸爸和妈妈的放水果操作是互斥关系，爸爸的放和女儿的吃、妈妈的放和儿子的吃必须连续执行。设置一个互斥信号量`plate`，初值为1表示允许放入一个水果；设置信号量`apple`和`orange`，初值为0表示盘子为空不许取，为1时可以取。

     ![image-20241003155401690](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003155401690.png?token=AVQM64MBERUR4ZLSXQ5MXXTHFIXW6)![image-20241003155416089](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003155416089.png?token=AVQM64N4CRLSZVFEZXL3MB3HFIXXC)

2. **读者-写者问题**

   * 问题描述：有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程同时访问共享数据时则可能导致数据不一致的错误。因此要求：①允许多个读者可以同时对文件执行读操作；②只允许一个写者往文件中写信息；③任意一个写者在完成写操作之前不允许其他读者或写者工作；④写者执行写操作前，应让己有的读者和写者全部退出。

   * 分析：写者与任何进程互斥；读者只与写者互斥，但与读者同步。设置`count`信号量记录当前读者数量，初值为0，同时设置互斥信号量`mutex`保护`count`更新时的互斥；设置互斥信号量`rw`保证读写互斥。

     ![image-20241003160046278](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003160046278.png?token=AVQM64LOTS7IUYYISFTHQBTHFIXXG)![image-20241003160213094](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003160213094.png?token=AVQM64J7FHS577ONIEAKL5DHFIXXK)

     上述实现过程中，读进程优先，只要有一个读进程活跃，随后而来的读进程都将被允许访问文件。这样的方式会导致写进程可能长时间等待， 且存在写进程“饿死”的情况。

     若希望当有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求，等到己在共享文件的读进程执行完毕，立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。为此，增加一个信号量`w`并在上面程序的`writer()`和`reader()`函数中各增加一对PV操作。换句话说`w`是读者和写者共同的排队队列，但当轮到自己访问时，仍然要看`rw`是否可用。有些书将这个算法称为**读写公平法**。

     ![image-20241003161854651](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003161854651.png?token=AVQM64KD3GW2F43GYA65AXDHFIXXO)

3. **哲学家进餐问题**

   * 问题描述：一张圆桌边上坐着5名哲学家，每两名哲学家之间的桌上摆一根筷子，两根筷子中间是一碗米饭。哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时， 才试图拿起左、右两根筷子（一根一根地拿起）。若筷子已在他人手上，则需要等待。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐，进餐完毕后，放下筷子继续思考。

   * 分析：哲学家对与邻居共享的筷子的访问是互斥关系。本题的关键是防止死锁或饥饿现象的发生。定义互斥信号量数组chopstick[5] = (1, 1, 1, 1, 1)，用于对5个筷子的互斥访问。哲学家按顺序编号为0~4,哲学家$i$左边筷子的编号为$i$，哲学家右边筷子的编号为$(i + 1)\%5$​​。为防止死锁发生，可以对哲学家进程施加一些限制条件：比如至多允许4名哲学家同时进餐；仅当一名哲学家左右两边的筷子都可用时，才允许他抓起筷子；对哲学家顺序编号，要求奇数号哲学家先拿左边的筷子，然后拿右边的筷子，而偶数号哲学家刚好相反。

     若采取当一名哲学家左右两边的筷子都可用时，才允许他抓起筷子：

     ![image-20241003163324363](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003163324363.png?token=AVQM64PNLILPWF2DCTR4K5THFIXXS)![image-20241003163348238](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003163348238.png?token=AVQM64NRQJ2EALMHDYDZMNLHFIXXW)

4. **吸烟者问题**

   * 问题描述：假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，此时供应者就会将另外两种材料放到桌上，如此重复（使三个抽烟者能够**轮流**抽烟）。

   * 分析：供应者与三个抽烟者分别是同步关系，三个抽烟者对抽烟动作互斥。用三个信号量`offer1, offer2, offer3`表示供应者提供的三种组合；用信号量`finish`表示互斥抽烟动作。

     ![image-20241003164345206](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003164345206.png?token=AVQM64LCSK4MX7BYMEQBONDHFIXX2)![image-20241003164427180](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003164427180.png?token=AVQM64OP6X3PSM2SNIUXDQ3HFIXYI)

## 2.4 死锁

### 2.4.1 死锁的概念

* 定义：多个进程因**竞争资源**而造成的一种僵局（**互相等待**），若无外力作用，这些进程都将无法向前推进。

* 产生原因：

  * 系统资源的竞争：对**不可剥夺资源**的竞争才可能产生死锁。
  * 进程推进顺序非法 ：进程在运行过程中请求和释放资源的**顺序不当**同样会导致死锁。**信号量使用不当**同样会导致死锁。

* **死锁产生的必要条件**：死锁产生必须**同时满足**以下4个条件。

  1. **互斥条件**：进程要求对所分配的资源（如打印机）进行排他性使用。

  2. **不剥夺条件**：进程所获得的资源在未使用完之前，不能被其他进程强行夺走。

  3. **请求并保持条件**：进程己经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。

  4. **循环等待条件**：存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。 

     注意，循环等待只是死锁的必要条件。死锁要求进程$P_i$等待的资源只能由$P_{i+1}$满足，而循环等待中等待$P_{i+1}$释放资源可能不是$P_i$的唯一选择，如下图所示。

     ![image-20241003182300247](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003182300247.png?token=AVQM64OOMUZM2VGOJCMSAE3HFIXYK)

* 处理策略：

  1. **死锁预防**：设置某些限制条件，破坏产生死锁的4个必要条件中的一个或几个。
  2. **避免死锁**。在资源的动态分配过程中，用某种方法防止系统进入不安全状态。
  3. **死锁的检测及解除**。无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。

  预防死锁和避免死锁都属于**事先预防策略**，预防死锁的限制条件比较严格，实现起来较为简单，但往往导致系统的效率低，资源利用率低；避免死锁的限制条件相对宽松，资源分配后需要通过算法来判断是否进入不安全状态，实现起来较为复杂。

  ![image-20241003182605689](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003182605689.png?token=AVQM64IUPGCS3RAT6YUVFUDHFIXYO)

### 2.4.2 死锁预防

* 破坏互斥条件：不可行，因为有些资源只能互斥使用，再有些场合应该保护这种互斥性。
* 破坏不剥夺条件：当一个己保持了某些不可剥夺资源的进程请求新的资源而得不到满足时，它必须释放己经保持的所有资源，待以后需要时再重新申请。
  * 缺点：实施较复杂，反复地申请和释放会增加系统开销，降低系统吞吐量。
  * 适用范围：状态易于保存和恢复的资源，如CPU寄存器、内存资源。
* 破坏请求并保持条件：采用**预先静态分配**方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行。一旦投入运行，这些资源就一直归它所有，不再提出其他资源请求。
  * 优点：实现简单。
  * 缺点：系统资源被严重浪费；会导致“饥饿”现象。
* 破坏循环等待条件：采用**顺序资源分配**法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完。
  * 缺点：编号必须相对稳定，限制了新类型设备的增加；经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费；给用户的编程带来麻烦。

### 2.4.3 死锁避免

避免死锁同样属于事先预防策略，但并不是事先采取某种限制措施破坏死锁的必要条件，而是在**资源动态分配过程中**，防止系统进入不安全状态，以避免发生死锁。这种方法所施加的限制条件较弱，可以获得较好的系统性能。

* **系统安全状态**：所谓安全状态，是指系统能按某种进程推进顺序为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成。此时称该推进顺序为**安全序列**。若系统无法找到一个安全序列，则称系统处于**不安全状态**。若此次分配不会导致系统进入不安全状态，则允许分配；否则让进程等待。

  * 假设系统中有三个进程P1, P2和P3，共有12台磁带机。进程P1共需要10台磁带机，P2和P3分别需要4台和9台。假设在T时刻，进程P1，P2和P3己分别获得5台、2台和2台，尚有3台未分配。那么，在T时刻系统是安全的，因为存在一个安全序列P2, P1, P3。

  * 若在T时刻，系统分配1台给P3，则系统进入不安全状态，因为无法找到一个安全序列。

    ![image-20241003193445067](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241003193445067.png?token=AVQM64IODTSN5I26IEJIXGLHFIXYQ)

  * 系统处于安全状态，就**一定不会**进入死锁状态；系统处于不安全状态，也只是**可能**进入死锁状态。

* **银行家算法**：把操作系统视为银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家制定的规则为进程分配资源。进程运行之前先声明对各种资源的最大需求量，当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和**是否超过**该进程**声明的最大需求量**。若超过则拒绝分配资源，若未超过则再测试系统**现存的资源能否满足**该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。

  * 数据结构描述：

    * 可利用资源向量`Available`：含m个元素的数组。`Available[j]=K`表示系统**现有**j类资源K个。
    * 最大需求矩阵`Max`：n×m矩阵，表示n个进程中每个进程对m类资源的**最大需求**。`Max[i,j]=K`表示进程i需要j类资源的最大数目为K。
    * 分配矩阵`Allocation`：n×m矩阵，表示每类资源当前**已分配**给每个进程的资源数。`Allocation[i,j]=K`表示进程i已分得j类资源的数目为K。
    * 需求矩阵`Need`：n×m矩阵，表示每个进程接下来最多还需要多少资源。`Need[i,j]=K`表示进程i还需要j类资源的数目为K。

    可见，`Need = Max - Allocation `。一般情况下，分配矩阵和最大需求矩阵是已知的，求出需求矩阵是解题的第一步。

  * 算法描述：设`Request_i`是进程`P_i`的请求向量，`Request_i[j]=K`表示进程`P_i`需要j类资源K个。收到请求向量后，系统按下述步骤进行检查：

    1. 若`Request_i[j] ≤ Need[i,j]`，继续下一步骤；否则认为出错。

    2. 若`Request_i[j] ≤ Availavle[j]`，继续下一步骤；否则表示尚无足够资源，`P_i`需等待。

    3. 系统**试探**着把资源分配给`P_i`，并修改数据结构数值：

       `Available = Available - Request `;

       `Allocation[i,j] = Allocation[i,j] + Request_i[j]`;

       `Need[i,j] = Need[i,j] - Request_i[j]`;

    4. 系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才**正式**将资源分配给进程`P_i`以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程`P_i`等待。

* 安全性算法举例

  ![image-20241004164750429](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004164750429.png?token=AVQM64MENZERTWCGJHRZEQLHFIXYU)

  ![image-20241004164757787](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004164757787.png?token=AVQM64JMOVE7BKL6DDNJG3LHFIXYW)

  ![image-20241004165034136](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004165034136.png?token=AVQM64NKKQQVDRKURP5NNJTHFIXY2)

* 银行家算法举例

  ![image-20241004165605589](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004165605589.png?token=AVQM64I35VED2I3WOMHW4MDHFIXY4)

![image-20241004165616768](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004165616768.png?token=AVQM64IVFOP6CD72257TMZDHFIXZA)

### 2.4.4 死锁检测和解除

若系统为进程分配资源时不采取任何措施，则应该提供死锁检测和解除的手段。

* 资源分配图：用圆圈代表一个进程，用框代表一类资源，框中的一个圆代表一类资源中的一个资源。从进程到资源的有向边称为**请求边**，表示该进程申请**一个单位**的该类资源；从资源到进程的边称为**分配边**，表示该类资源已有一个资源分配给了该进程。

  下图中，P1从R1处分得了两个资源，并请求一个R2资源；P2从R1和R2分别分得一个资源，并请求一个R1资源。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004171124599.png?token=AVQM64M5CURAQFYNW47QOTDHFIXZE" alt="image-20241004171124599" style="zoom:50%;" />

* 死锁定理：S为死锁的条件是当且仅当S状态的资源分配图是**不可完全简化**的。

  简化资源分配图可检测系统状态S是否为死锁状态。简化方法如下：

  1. 找出资源分配图中**既不阻塞又不孤点**的进程，即该进程申请的资源数量小于等于空闲资源数量（空闲量=资源最大数量-资源出度）。将该点的所有请求边和分配边消去，使之成为孤立结点。上图中，P1是唯一满足的进程。
  2. 被步骤1孤立的进程所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。接着，对剩余的非阻塞非孤立节点重复上述操作。若最终能消去图中所有的便，则称该图是**可完全简化的**。上图中，P2就可以被唤醒变为非阻塞进程，并消去图中的所有边。

  ![image-20241004172503522](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004172503522.png?token=AVQM64IMBKMIHR3FMD6TD43HFIXZI)

* 死锁解除：死锁解除的主要方法有：
  * 资源剥夺法：**挂起**某些死锁进程，并**剥夺**它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源而处于资源匮乏的状态。
  * 撤销进程法：强制撤销部分甚至全部死锁进程并**剥夺**这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。
  * 进程回退法：让一（或多）个进程回退到足以回避死锁的地步，进程回退时**自愿释放资源**而非被剥夺。要求系统保持进程的历史信息，设置还原点。

# 第 3 章 内存管理

## 3.1 内存管理概念

### 3.1.1 基本原理和要求

操作系统对内存的划分和动态分配，就是内存管理的概念。内存管理的主要功能有：

* 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配，提高编程效率。
* 地址转换：提供地址变换功能，把逻辑地址转换成相应的物理地址。
* 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。
* 内存共享：支持多个进程对内存共享区域进行受控访问。
* 存储保护：保证各道作业在各自的存储空间内运行，互不干扰。

在进行具体的内存管理之前，需要了解进程运行的基本原理和要求。

1. **程序的链接与装入**：创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：

   <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241004201015558.png?token=AVQM64JPZKFTIWI2KXQXMY3HFIXZK" alt="image-20241004201015558" style="zoom:67%;" />

   * **编译**。编译程序将用户源代码编译成若干目标模块。需要解决两个问题：①修改**相对地址**，编译后的*所有目标模块都是从0开始的相对地址*，当链接成一个装入模块时要修改相对地址。②变换外部调用符号，将每个模块中所用的外部调用符号也都变换为相对地址。

   * **链接**。链接程序将编译后的目标模块和它们所需的库函数链接在一起，形成完整的装入模块。链接有三种方式：
     * **静态链接**：各目标模块与它们所需库函数链接成完整装入模块后**不再拆开**。
     * **装入时动态链接**：在装入内存时，采用边装入边链接的方式。其优点是便于修改和更新，便于实现对目标模块的共享。
     * **运行时动态链接**：在程序执行中需要该目标模块时才进行链接。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到装入模块上。其优点是能加快程序的装入过程， 还可节省大量的内存空间。
     
   * **装入**。装入程序将装入模块装入内存运行。装入有三种方式：
     * **绝对装入**：只适用于单道程序环境。即逻辑地址与实际内存地址**完全相同**的装入方法，因此不需对程序和数据的地址进行修改。（显然，多道程序将会有多个从0开始的起始地址，无法使所有程序的逻辑地址与实际内存地址相同）
     
     * **可重定位装入**：多道程序环境下，根据内存的当前情况，将装入模块装入内存的适当位置。在装入时对目标程序中指令和数据地址的修改过程称为**重定位**，又因为地址变换通常是在进程装入时一次完成的，故称为**静态重定位**。
     
     * **动态运行时装入**：也称**动态重定位**。程序在内存中若发生移动，则需要采用动态的装入方式。装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要**执行时才进行**。因此，装入内存后的所有地址均为相对地址。这种方式需要一个**重定位寄存器**的支持。
     
       * 优点：可以将程序分配到不连续的存储区；在程序运行之前可以只装入部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享。
     
       ![image-20241005100702593](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241005100702593.png?token=AVQM64MX7KM2MKBMSBJ5K73HFIXZO)

2. **逻辑地址与物理地址**：

   * **逻辑地址**：编译后，每个目标模块都从0号单元开始编址，这称为该目标模块的**相对地址**（或**逻辑地址**）。 当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从0号单元开始编址的**逻辑地址空间**（或**虚拟地址空间**），对于32位系统，逻辑地址空间的范围为$0\sim 2^{32}- 1$。进程在运行时，看到和使用的地址都是逻辑地址。*不同进程可以有相同的逻辑地址*，因为这些相同的逻辑地址可以映射到主存的不同位置。 
   * **物理地址空间**：内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取。将逻辑地址转换成物理地址的过程称为**地址重定位**。
   * 操作系统通过**内存管理部件**（**MMU**）将进程使用的逻辑地址转换为物理地址。逻辑地址通过**页表**映射到物理内存，页表由操作系统维护并被处理器引用。

3. **进程的内存映像**：当一个程序调入内存运行时，就构成了进程的内存映像。一个进程的内存映像一般有几个要素：

   * **代码段**：即程序的二进制代码，代码段是**只读**的，可以被多个进程**共享**。 
   * **数据段**：即程序运行时加工处理的对象，**包括全局变量和静态变量**。 
   * **进程控制块（PCB）**：存放在系统区。操作系统通过PCB来控制和管理进程。
   * **堆**：用来存放**动态分配的变量**。通过调用malloc函数动态地向高地址分配空间。 
   * **栈**：用来实现**函数调用**。从用户空间的最大地址往低地址方向增长。

   代码段和数据段的大小是固定的，堆和栈是可动态扩展和收缩的。例如：调用malloc，堆扩展；调用free，堆收缩。调用一个函数时，栈增长；从一个函数返回时，栈收缩。

   注意区别**进程映像**和**进程的内存映像**，虽然它们结构类似。进程映像（进程实体）是储存在磁盘上的静态数据结构，因为它并没有运行。进程的内存映像是内存上的动态数据结构，数据会随着运行过程发生改变。

   下图是一个进程在内存中的映像。其中，共享库用来存放进程用到的共享函数库代码，如`printf()`函数等。在只读代码段中，`.init`是程序初始化时调用的`_init`函数；`.text`是用户程序的机器代码；`.rodata`是只读数据。在读/写数据段中，`.data`是己初始化的全局变量和静态变量；`.bss`是未初始化及所有初始化为0的全局变量和静态变量。

   <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241005103921268.png?token=AVQM64PBEMTKEXKQPQOIUMTHFIXZS" alt="image-20241005103921268" style="zoom:67%;" />

4. **内存保护**：确保每个进程都有一个单独的内存空间。保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。内存保护可采取两种方法：

   * 在CPU中设置一对**上、下限寄存器**，存放用户作业在主存中的**下限和上限地址**，每当CPU要访问一个地址时，分别和两个寄存器的值相比，判断有无越界。
   * 采用**重定位寄存器**（又称**基地址寄存器**）和**界地址寄存器**（又称**限长寄存器**）。重定位寄存器含**最小的物理地址值**，界地址寄存器含**逻辑地址的最大值**。内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。

   <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006123457197.png?token=AVQM64KMGC2MRIJASHFFZYTHFIXZU" alt="image-20241006123457197" style="zoom:67%;" />

   也就是说，上下限寄存器是同时比较上限和下限，而界地址寄存器是直接比较（上限-下限），判断合法后再通过重定位寄存器加上下限。

   加载重定位寄存器和界地址寄存器时必须使用**特权指令**，只有操作系统内核才可以加载这两个存储器。这种方案允许操作系统内核修改这两个寄存器的值，而不允许用户程序修改。

5. **内存共享**：只有只读的区域才可以共享。**可重入代码**又称**纯代码**，是一种允许多个进程同时访问但不允许被任何进程修改的代码。但在实际执行时，也可以为每个进程配以局部数据区，把在执行中可能改变的部分复制到该数据区，这样，程序在执行时只需对该私有数据区中的内存进行修改，并不去改变共享的代码。

   内存共享可以极大节省内存开销。假设若干个用户系统同时执行一个文本编辑程序，该程序有纯代码，则整个系统只需保留一份纯代码副本，每个进程建立页表项时，使对应数量的页表项指向共享代码区的物理页号即可。

6. **内存分配与回收**：单道程序操作系统：单一连续分配，多道程序操作系统：固定分区分配。为了更好地适应不同大小的程序要求，又发展了**动态分区分配**。为了更好地提高内存的利用率，进而从**连续分配方式**发展到**离散分配方式**一一**页式存储管理**。引入分段存储管理的目的，主要是为了满足用户在编程和使用方面的要求，其中某些要求是其他几种存储管理方式难以满足的。

### 3.1.2 覆盖与交换*

覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。

* 覆盖：由于程序运行时并非任何时候都要访问程序及数据的各个部分，因此可把用户空间分成一个**固定区**和若干**覆盖区**。将**经常活跃的**部分放在**固定区**， 其余部分按调用关系分段。首先将那些**即将要访问的**段放入**覆盖区**，其他段放在**外存**中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。

  * 特点：进程不需要将全部信息装入主存也能运行，但当同时运行程序的代码量大于主存时仍不能运行，此外，内存中能够更新的地方只有覆盖区的段，固定区会常驻内存。覆盖技术对用户和程序员不透明。

* 交换（对换）：把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又称**换出**；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称**换入**。中级调度采用的就是交换技术。 在理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。 

  交换需要注意以下问题：

  * 需要备份存储，通常是磁盘。
  * 每个进程的执行时间要比交换时间长，以确保有效使用CPU。
  * 换出进程必须确保该进程完全处于空闲状态，
  * 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用起来可能很快。
  * 通常在多个进程运行且内存空间吃紧时启动，系统负荷降低时就暂停。
  * 普通的交换使用不多，但交换策略的变体在UNIX等系统中仍发挥作用。

交换技术主要在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。对于主存无法存放用户程序的矛盾，现代操作系统是通过**虚拟内存技术**来解决的，覆盖技术则已成为历史；而交换技术在现代操作系统中仍具有较强的生命力。

### 3.1.3 连续分配管理方式

连续分配方式是指为一个用户程序分配一个连续的内存空间，主要包括单一连续分配、固定分区分配和动态分区分配。

* **单一连续分配**：内存分为系统区和用户区，系统区仅供操作系统使用，通常在低地址部分；在用户区内存中，仅有一道用户程序，即整个内存的用户空间由该程序独占。

  * 优点：简单、无**外部碎片**（存在于所有分区的外部，由于太小而无法分配给进程的空闲内存区域，这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址**不连续**或其他原因，使得系统无法满足当前申请），无需进行内存保护。
  * 缺点：只能用于单用户、单任务操作系统；有**内部碎片**（存在于分区的内部，由于分配给进程的内存比进程实际需要的内存多而产生的内存浪费）；存储器利用率极低。

* **固定分区分配**：它将用户内存空间划分为若干固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可再从外存的后备作业队列中选择适当大小的作业装入该分区，如此循环。在划分分区时有两种不同的方法：

  1. 分区大小相等。程序太小会造成浪费，程序太大又无法装入，缺乏灵活性。
  2. 分区大小不等。划分为多个较小的分区、适量的中等分区和少量大分区。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006153930156.png?token=AVQM64IM7BYD65YX3SDFQFTHFIXZY" alt="image-20241006153930156" style="zoom: 67%;" />

  通常会建立一张分区使用表以供检索并进行分配。若能找到合适的未分配分区，则将其分配给程序，并将状态置为“已分配”；若不能找到，则拒绝分配。回收内存时，将对应状态置为“未分配”。

  * 优点：最简单的多道程序设计的存储分配；无外部碎片。

  * 缺点：程序可能太大而放不进任何一个分区；有内部碎片。

* **动态分区分配**：又称**可变分区分配**，它是在进程装入内存时，根据进程的实际需要，动态地为之分配内存， 并使分区的大小正好适合进程的需要。因此，系统中分区的大小和数目是可变的。 

  随着时间推移，进程不断换入换出，内存中会产生越来越多小的外部碎片，内存的利用率也随之下降。克服外部碎片可以通过**紧凑技术**来解决，即操作系统不时地对进程进行移动和整理。但这需要**动态重定位寄存器**的支持，且相对费时。紧凑的过程实际上类似于Windows系统中的磁盘碎片整理程序，只不过后者是对外存空间的紧凑。

  ![image-20241006155750260](https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006155750260.png?token=AVQM64N3SDWCJCSURZINPGDHFIXZ2)

  * 在进程装入或换入主存时，若内存中有多个足够大的空闲块，则操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略。考虑以下几种算法：
    * **首次适应（First Fit）算法**：以地址递增顺序链接空闲分区，从**链首开始**查找到的第一个满足要求的空闲分区分配给作业。
      * 优点：通常最好、最快。
      * 缺点：会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时都要经过这些分区，因此增加了开销。
    * **邻近适应（Next Fit）算法**：又称**循环首次适应算法**，由首次适应算法演变而成。不同之处是，分配内存时从**上次查找结束的位置开始**继续查找。
      * 缺点：常常导致在内存空间的尾部分裂成小碎片。通常比首次适应算法要差。
    * 最佳适应（Best Fit）算法：以容量递增的顺序链接空闲分区，从**链首开始**查找到的第一个能满足要求的空闲分区分配给作业，避免大材小用。
      * 缺点：性能通常很差，每次最佳的分配会留下很小的难以利用的内存块，会产生**最多的外部碎片**。
    * 最坏适应（Worst Fit）算法：与最佳适应算法相反，以容量递减的顺序链接空闲分区。
      * 优点：最不容易产生碎片。
      * 缺点：会很快导致没有可用的大内存块，因此性能也非常差。 
  * 动态分区分配会设置一张空闲分区链表，并按起始地址排序。
  * 分配内存时，检索空闲分区链，找到所需的分区，若其大小大于请求大小，便从该分区中按请求大小分割一块空间分配给装入进程（若剩余部分小到不足以划分，则无须分割），余下部分仍留在空闲分区链中。回收内存时，根据回收分区的起始地址从链表中找到插入点，有四种情况：①回收区与插入点的前一空闲分区相邻，将这两个分区合并，并修改前一分区表项的大小为两者之和；②回收区与插入点的后一空闲分区相邻，将这两个分区合并，并修改后一分区表项的始址和大小；③回收区同时与插入点的前、后两个分区相邻，此时将这三个分区合并，修改前一分区表项的大小为三者之和，取消后二分区表项；④回收区没有相邻的空闲分区，此时应为回收区新建一个表项，填写始址和大小，并插入空闲分区链。 

连续分配方式中，即使内存有超过需求内存大小的空闲空间，但若没有需求内存大小的连续空闲空间，作业仍无法运行。若采用非连续分配方式，虽然可以运行，但也需要额外的空间去存储分散区域的索引，使得非连续分配方式的**存储密度低于连续分配方式**。

非连续分配方式根据分区的大小是否固定，分为**分页存储管理**和**分段存储管理**。在分页存储管理中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行，分为**基本分页存储管理**和**请求分页存储管理**。

### 3.1.4 基本分页存储管理

为了尽量避免内存碎片产生，引入了分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但这种碎片相对于进程来说也是很小的，每个进程**平均只产生半个块大小的内部碎片**（也称**页内碎片**）。

* 页面与页面大小：进程中的块称为**页**或**页面（Page）**，内存中的块称为**页框**或**页帧（Page Frame）**，外存也以同样的单位进行划分，直接称为**块**或**盘块（Block）**。进程在执行时需要申请主存空间，即要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。 

  为方便地址转换，页面大小应是**2的整数幂**。同时页面大小应该适中，页面太小会使进程的页面数过多，这样页表就会过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率；页面过大又会使页内碎片增多，降低内存的利用率。

* **逻辑地址结构**：包含两部分：前一部分为**页号**$P$，后一部分为**页内偏移量**$W$。地址长度为32位， 其中0〜11位为页内地址，即每页大小为4KB（$2^{10}=4\times2^{10}$）； 12〜31位为页号，即最多允许$2^{20}$页。地址结构决定了虚拟内存的寻址空间有多大。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006171933969.png?token=AVQM64MCWUNDX43CRBZYCLDHFIXZ6" alt="image-20241006171933969" style="zoom:67%;" />

* **页表**：实现从页号到物理块号的地址映射。系统为每个进程建立一张页表，它记录页面在内存中对应的**物理块号**，页表一般**存放在内存中**。页表中的每一行为一个页表项，页表项同样由两部分组成：前一部分为页号，后一部分为物理内存的块号。页表项的第二部分（物理内存块号）与地址的第二部分（页内偏移量）共同组成物理地址。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006180146785.png?token=AVQM64KD4MM4TU5GJ2YQ5XLHFIX2C" alt="image-20241006180146785" style="zoom:67%;" />

* **基本地址变换机构**：借助页表将逻辑地址转换为内存中的物理地址。

  在系统中通常设置一个**页表寄存器（PTR）**，存放页表在内存的起始地址$F$和页表长度$M$​。平时，进程未执行时，页表的始址和页表长度存放在**本进程的PCB中**，当进程被调度执行时，才将页表始址和页表长度装入页表寄存器中。假设页面大小为$L$，逻辑地址$A$到物理地址$E$的变换过程如下：

  1. 计算页号$P$和页内偏移量$W$。
  2. 若$P\geq M$，则产生越界中断，否则继续执行。
  3. 页表中页号$P$对应的页表项地址=页表起始地址$F$+页号$P\times$页表项长度（页地址占用的存储空间）。
  4. 根据页表项计算$E=b\times L+W$。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006173024841.png?token=AVQM64ND26QSVJXY5SJB2PLHFIX2E" alt="image-20241006173024841" style="zoom:67%;" />

  例如，若页面大小为1KB，页号2对应的物理块为b = 8，计算逻辑地址$A = 2500$的物理地址$E$的过程如下：$P = 2500/1K = 2, W=2500\%1K =452$，查找得到页号2对应的物理块的块号为8，$ E=8\times1024 + 452 = 8644$。

  页表项的大小不是随意规定的，而是有所约束的。以32位逻辑地址空间、字节编址单位、一页4KB为例，地址空间内一共有$ 2^{32}B/4KB = 1M$页，因此需要$ \log_2M = 20$位才能保证表示范围能容纳所有页面，又因为以字节作为编址单位，即页表项的大小$ \geq\lceil 20/8\rceil = 3B$。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于或等于3B。为了方便存储，一般会进一步取成**4B**（2的整数幂），这样也能够容纳一些其他信息。

* **分页管理的问题**：①每次访存操作都需要进行逻辑地址到物理地址的转换，**地址转换过程必须足够快**，否则访存速度会降低；②每个进程引入页表，用于存储映射机制，**页表不能太大**，否则内存利用率会降低。

* **具有快表的地址变换机构**：若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次内存：第一次是访问页表，第二次是根据页表计算的物理地址地址存取数据或指令。显然，这种方法比通常执行指令的速度慢了一半。 

  为此，在地址变换机构中增设一个具有**并行查找能力**的高速缓冲存储器一一**快表**，又称**相联存储器（TLB）**，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表常称为**慢表**。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006184451608.png?token=AVQM64OSY32EC7TBD7M2YMTHFIX2G" alt="image-20241006184451608" style="zoom:67%;" />

  具有快表的分页机制中，地址的变换过程：

  1. CPU给出逻辑地址后，由硬件进行地址转换，将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行**比较**。 
  2. 若找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。
  3. 若未找到匹配的页号，则需要访问主存中的页表，读出页表项后，应同时将其**存入快表**，以便后面可能的再次访问。若快表已满，则须按特定的算法**淘汰**一个**旧页表项**。

  有些处理机设计为快表和慢表同时查找，若在快表中查找成功则终止慢表的查找。一般快表的命中率可达90%以上，其有效性基于著名的**局部性原理**。

* **二级页表**：为了压缩页表，进一步延伸页表映射的思想，就可得到二级页表。为查询方便，顶级页表**最多只能有1个页面**，因此顶级页表总共可以容纳4KB/4B = 1K个页表项，它占用的地址位数为$\log_21K = 10$位，而之前己经计算出页内偏移地址占用了12位，因此一个32位的逻辑地址空间就剩下了10位，正好使得**二级页表的大小在一页之内**，这样就得到了逻辑地址空间的格式。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006190133154.png?token=AVQM64NH4GOUONMBPZ4DFYDHFIX2K" alt="image-20241006190133154" style="zoom:67%;" />

  建立多级页表的目的在于建立索引，以便不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006190456847.png?token=AVQM64LTY2EPJTRPLAYFEYLHFIX2M" alt="image-20241006190456847" style="zoom:67%;" />

### 3.1.5 基本分段存储管理

分页通过硬件机制实现，对用户完全透明。分段管理方式的提出则考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。

* **分段**：段式管理方式按照**用户进程中的自然段**划分逻辑空间。例如，用户进程由主程序段、两个子程序段、栈段和数据段组成，于是可以把这个用户进程划分为5段，每段从0开始编址，并分配一段连续的地址空间（**段内要求连续，段间不要求连续**，因此整个作业的地址空间是**二维**的），其逻辑地址由段号$S$与段内偏移量$W$两部分组成。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006191052934.png?token=AVQM64N26XGEFP5OISVXFUTHFIX2Q" alt="image-20241006191052934" style="zoom:67%;" />

  在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须**由用户显式提供**，在高级程序设计语言中，这个工作由编译程序完成。

* **段表**：每个进程都有一张逻辑空间与内存空间映射的段表，其中每个段表项对应进程的一段，段表项记录该段在内存中的始址和长度。段表用于实现从逻辑段到物理内存区的映射，执行中的进程可通过查找段表，找到每段所对应的内存区。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006191218367.png?token=AVQM64ODCFCSZZGPTATJ7YLHFIX2S" alt="image-20241006191218367" style="zoom:67%;" />

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006191316224.png?token=AVQM64OC3L3FK4JWCJD3SBLHFIX2U" alt="image-20241006191316224" style="zoom:67%;" />

* **地址变换机构**：为了实现进程从逻辑地址到物理地址的变换功能， 在系统中设置了段表寄存器，用于存放段表始址$F$和段表长度$M$。逻辑地址$A$到物理地址$E$的变换过程如下：

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241006192622851.png?token=AVQM64L3QX57RQBK2DS4J5THFIX2Y" alt="image-20241006192622851" style="zoom:67%;" />

  1. 从逻辑地址$A$中取出段号$S$和段内偏移量$W$。
  2. 若$S\geq M$，则产生越界中断，否则继续执行。
  3. 段号$S$对应的段表项地址=段表始址$F$+段号$S\times$段表项长度，从而找到对应段表项，并得到段长$C$和始址$b$。若$W\geq C$，则产生越界中断，否则继续执行。
  4. 计算$E=b+W$，用得到的物理地址去访问内存。

* **段的共享与保护**：在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。纯代码（可重入代码）和不能修改的数据可以共享，而可修改的代码和数据不能共享。

  与分页管理类似，分段管理的保护方法主要有两种：一种是**存取控制保护**，另一种是**地址越界保护**。地址越界保护将段表寄存器中的**段表长度**与逻辑地址中的**段号**比较，若段号大于段表长度，则产生越界中断；再将段表项中的**段长**和逻辑地址中的**段内偏移**进行比较，若段内偏移大于段长，也会产生越界中断。分页管理只需要判断页号是否越界，**页内偏移是不可能越界的**。

  与页式管理不同，段式管理不能通过给出一个整数便确定对应的物理地址，因为**每段的长度是不固定的**，无法通过整数除法得出段号，无法通过求余得出段内偏移，所以**段号和段内偏移一定要显式给出**，因此分段管理的地址空间是**二维**的。

### 3.1.6 段页式管理

将分页存储管理与分段存储管理结合起来，便形成了段页式存储管理方式。

在段页式系统中，作业的地址空间首先被分成若干逻辑段，每段都有自己的段号，然后将每段分成若干大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干和页面大小相同的存储块，对内存的分配以存储块为单位。

在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241007144730110.png?token=AVQM64NYJM3LR2MKAHQM3JDHFIX26" alt="image-20241007144730110" style="zoom:67%;" />

为了实现地址变换，系统为每个进程建立一张段表，每个分段有一张页表。段表表项中至少包括段号、页表长度和页表始址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表始址和段表长度。（在一个进程中，段表只有一个，而页表可能有多个）

在进行地址变换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最后形成物理地址。进行一次访问实际需要三次访问主存，这里同样可以使用快表来加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241007144933896.png?token=AVQM64PBMP65B6DQC7SZG53HFIX3A" alt="image-20241007144933896" style="zoom:67%;" />

综上可以得出，段页式管理的地址空间是**二维**的。

## 3.2 虚拟内存管理

### 3.2.1 虚拟内存基本概念

* **传统存储管理方式的特征**：**一次性**和**驻留性**。

  * 一次性：作业必须一次性全部装入内存后，才能开始运行。这导致①不能全部装入内存的作业无法运行；②大量作业要求运行时只能使少数作业先运行。
  * 驻留性：作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。运行中的进程会因等待I/O而被阻塞，可能处于长期等待状态。

* **局部性原理**：从广义上讲，快表、页高速缓存及虚拟内存技术都属于高速缓存技术，这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，又适用于数据结构。

  局部性原理表现在以下两个方面：

  * **时间局部性**。程序中的某条指令一旦执行，不久后该指令可能再次执行；某数据被访问过，不久后该数据可能再次被访问。产生的原因是程序中存在着大量的循环操作。
  * **空间局部性**。一旦程序访问了某个存储单元，在不久后，其附近的存储单元也将被访问， 即程序在一段时间内所访问的地址，可能集中在一定的范围之内，因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

  时间局部性通过将近来使用的指令和数据保存到高速缓存中，并使用高速缓存的层次结构实现。空间局部性通常使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上建立了“内存-外存”的两级存储器结构，利用局部性原理实现高速缓存。

* **虚拟存储器**：顾名思义，虚拟存储器是指由于系统提供了**部分装入、请求调入和置换**功能后（对用户透明），给用户的感觉是好像存在一个比实际物理内存大得多的存储器。但容量大只是一种错觉，是虚的。虚拟存储器有以下三个主要特征：

  * **多次性**：允许作业被分成多次调入内存运行，即只需将当前要运行的那部分程序和数据装入内存即可开始运行。以后每当要运行到尚未调入的那部分程序时，再将它调入。多次性是虚拟存储器**最重要的特征**。
  * **对换性**：无须在作业运行时一直常驻内存，在进程运行期间，允许将那些暂不使用的程序和数据从内存调至外存的对换区（换出），待以后需要时再将它们从外存调至内存（换进）。
  * **虚拟性**：从逻辑上扩充内存的容量，使用户所看到的内存容量远大于实际的内存容量。这是虚拟存储器所**表现出的最重要特征**，也是实现虚拟存储器的**最重要目标**。

* **虚拟内存技术的实现**：采用连续分配方式时，会使相当一部分内存空间都处于暂时或"永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实现需要建立在**离散分配的内存管理方式**的基础上，有三种方式：

  * **请求分页存储管理**
  * **请求分段存储管理**
  * **请求段页式存储管理**

  无论哪种方式，都需要以下几个方面的硬件支持：

  * 一定容量的内存和外存
  * 页表机制（段表机制）作为主要的数据结构
  * 中断机构
  * 地址变换机构

### 3.2.2 请求分页管理方式

请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了**请求调页功能**和**页面置换功能**。请求分页是目前**最常用**的一种实现虚拟存储器的方法。

在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存中时，再通过调页功能将其调入，同时还可通过置换功能将暂时不用的页面换出到外存上，以便腾出内存空间。

为了实现请求分页，系统必须提供一定的硬件支持：

* **页表机制**：为了发现和处理访问的页面不在内存中的情况，请求页表项增加了4个字段。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241007172000398.png?token=AVQM64KQM656O6Q452AUENLHFIX3C" alt="image-20241007172000398" style="zoom:67%;" />

  * **状态位**$P$：指示该页是否已调入内存，供**程序访问时**参考。
  * **访问字段**$A$​：记录本页在一段时间内被访问的次数，或记录本页最近己有多长时间未被访问，供**置换算法换出页面时**参考。
  * **修改位**$M$：标识该页在调入内存后是否被修改过，以确定**页面置换时**是否写回外存。
  * **外存地址**：指示该页在外存上的地址，通常是物理块号，供**调入该页时**参考。

* **缺页中断机构**：每当所要访问的页面不在内存中时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（**调页完成唤醒**），若内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中的相应页表项，若此时内存中没有空闲块，则要**淘汰**某页（若被淘汰页在内存期间被修改过，则要将其写回外存）。

  缺页中断属于中断，与一般中断相比有两个明显区别：

  * 在指令执行期间而非一条指令执行完后产生和处理中断信号，属于**内部异常**。
  * 一条指令在执行期间，可能产生多次缺页中断。

* **地址变换机构**：在分页系统地址变换机构的基础上，为实现虚拟内存， 又增加了某些功能而形成的，如产生和处理缺页中断，及从内存中换出一页的功能等等。 

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241007173550906.png?token=AVQM64KW4KWUDVN7EXXPCUTHFIX3G" alt="image-20241007173550906" style="zoom:67%;" />

  在地址变换时，首先检索快表：

  * 若找到要访问的页，则修改页表项中的访问字段$A$（写指令还需要重置修改位$M$），然后利用页表项中给出的物理块号和页内地址形成物理地址。 
  * 若未找到该页的页表项，则应到内存中去查找页表，再对比页表项中的状态位$P$，看该页是否己调入内存，若页面己调入，则将该页的页表写入快表，若快表己满，则需采用某种算法替换。若页面未调入，则产生缺页中断，请求从外存把该页调入内存。

### 3.2.3 页框分配

* 驻留集大小：对于分页式的虚拟内存，在进程准备执行时，不需要也不可能把一个进程的所有页都读入主存。因此，操作系统必须决定读取多少页，即决定给特定的进程分配几个**页框**。给一个进程分配的物理页框的集合就是这个进程的**驻留集**。需要考虑以下几点：
  * 分配给一个进程的页框越少，驻留在主存中的进程就越多，从而可提高CPU的利用率。
  * 若一个进程在主存中的页面过少，则尽管有局部性原理，缺页率仍相对较高。
  * 若分配的页框过多，则由于局部性原理，对该进程的缺页率没有太明显的影响。
* **内存分配策略**：在请求分页系统中，可采取两种内存分配策略，即固定和可变分配策略。在进行置换时，也可采取两种策略，即全局置换和局部置换。于是可组合出下面三种适用的策略。
  * **固定分配局部置换**：为每个进程分配一定数目的物理块，在进程运行期间都不改变。所谓局部置换，是指如果进程在运行中发生缺页，则只能从分配给该进程在内存的页面中选出**一页**换出，然后再调入一页， 以保证分配给该进程的**内存空间不变**。
    * 缺点：难以确定应为每个进程分配的物理块数目：太少会频繁出现缺页中断，太多又会降低CPU和其他资源的利用率。
  * **可变分配全局置换**：先为每个进程分配一定数目的物理块，在进程运行期间可根据情况适当地**增加或减少**。所谓全局置换，是指如果进程在运行中发生缺页，系统从空闲物理块队列中取出**一块**分配给该进程， 并将所缺页调入。
    * 优点：更加灵活，可以动态增加进程的物理块。
    * 缺点：会盲目地给进程增加物理块，导致系统多道程序的并发能力下降。
  * **可变分配局部置换**：为每个进程分配一定数目的物理块，当某进程发生缺页时，只允许从该进程在内存的页面中选出**一页**换出，因此不会影响其他进程的运行。若进程在运行中**频繁**地发生**缺页中断**，则系统再为该进程**分配**若干物理块，直至该进程的缺页率趋于适当程度；反之，若进程在运行中的**缺页率特别低**，则可适当**减少分配**给该进程的物理块，但不能引起其缺页率的明显增加。
    * 优点：在保证进程不会过多地调页的同时，也保持了系统的多道程序并发能力。
    * 缺点：实现更复杂，需要更大的开销，但对比频繁地换入/换出所浪费的计算机资源，这种牺牲是值得的。 
* 物理块调入算法：采用固定分配策略时，可以采用下述几种算法。
  * **平均分配算法**
  * **按比例分配算法**：根据**进程大小**按比例分配。
  * **优先权分配算法**：实际通常采取的方法是一部分按比例分配给各个进程，一部分则根据优先权分配。
* 调入页面的时机（WHEN）：可采取以下两种调页策略。
  * **预调页策略**：主要用于进程的**首次调入**，由程序员指出应先调入哪些页。
  * **请求调页策略**：缺页时提出请求再调页。由于易于实现，目前的虚拟存储器大多采用此策略。缺点是每次仅调入一页，增加了磁盘I/O开销。
* 从何处调入页面（WHERE）：请求分页系统中的外存分为两部分：用于存放文件的**文件区**和用于存放对换页面的**对换区**。对换区采用**连续分配方式**，而文件区采用**离散分配方式**，因此对换区的磁盘I/O速度比文件区的更快。这样，当发生缺页请求时，系统从何处将缺页调入内存就分为三种情况：
  * 系统拥有足够的对换区空间：在进程运行前，需将与该进程有关的文件**从文件区复制到对换区**。发生缺页请求时可以全部从对换区调入所需页面，以提高调页速度。
  * 系统缺少足够的对换区空间：凡是**不会被修改**的文件都直接从**文件区**调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些**可能被修改**的部分，在将它们换出时须**调到对换区**，以后需要时再从对换区调入（因为读比写的速度快）。
  * UNIX方式：与进程有关的文件都放在文件区，因此**未运行过**的页面都应从**文件区**调入。 **曾经运行过**但又被换出的页面，由于是放在**对换区**，因此在下次调入时应从对换区调入。 进程请求的**共享页面**若被其他进程调入内存，则**无须**再从对换区**调入**。
* 如何调入页面（HOW）：当进程所访问的页面不在内存中时（存在位为0），便向CPU发出缺页中断，中断响应后便转入缺页中断处理程序。该程序通过查找页表得到该页的物理块，此时如果内存未满，则启动磁盘I/O，将所缺页调入内存，并修改页表。如果内存已满，则先按某种**置换算法**从内存中选出一页准备换出；如果该页未被修改过（修改位为0），则无须将该页写回磁盘；但是，如果该页己被修改（修改位为1），则必须将该页写回磁盘，然后将所缺页调入内存，并修改页表中的相应表项， 置其存在位为1。调入完成后，进程就可利用修改后的页表形成所要访问数据的内存地址。

### 3.2.4 页面置换算法

好的页面置换算法应有**较低的页面更换频率**，也就是说，应将以后不会再访问或以后较长时间内不会再访问的页面先调出。 常见的置换算法有以下4种。

* **最佳（OPT）置换算法**：选择的被淘汰页面是以后**永不使用**的页面，或是在**最长时间内不再被访问**的页面，以便保证获得最低的缺页率。

  * 缺点：由于人们目前**无法预知**进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法**无法实现**。但可利用该算法去**评价其他算法**。 

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241007190909815.png?token=AVQM64OOY5IYAX3QXNGNXL3HFIX3K" alt="image-20241007190909815" style="zoom:67%;" />

* **先进先出（FIFO）页面置换算法**：优先淘汰**最早进入**内存的页面，即淘汰在内存中**驻留时间最久**的页面。

  * 优点：实现简单，只需把已调入内存的页面根据先后次序链接成**队列**（基于队列实现），设置一个指针总是指向最老的页面。

  * 缺点：与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。

  * FIFO算法还会产生所分配的物理块数增大而页故障数不减反增的异常现象，称为**Belady异常**。只有FIFO算法**可能出现**Belady异常。页面访问顺序为3, 2, 1, 0, 3, 2, 4, 3, 2, 1, 0, 4。若采用FIFO置换算法，当分配的物理块为3个时，缺页次数为9次；当分配的物理块为4个时，缺页次数为10次。分配给进程的物理块增多，但缺页次数不减反增。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241007191907346.png?token=AVQM64KLOEM2J4WMNEQYGCTHFIX3O" alt="image-20241007191907346" style="zoom:67%;" />

* **最近最久未使用（LRU）置换算法**：选择**最近最长时间未访问过**的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。淘汰页面时选择现有页面中**访问字段值最大**的予以淘汰。

  * LRU算法根据各页以前的使用情况来判断，是"向前看”的，而OPT算法则根据各页以后的使用情况来判断，是''向后看”的。
  * 优点：性能较好。LRU是堆栈类的算法。理论上可以证明，**堆栈类算法不可能出现Belady异常**。
  * 缺点：为了对所有的页进行排序以选出最近最长未访问页面，需要寄存器和栈的硬件支持，实现开销大。

* **时钟（CLOCK）置换算法**：试图用比较小的开销接近LRU算法性能的算法，都是CLOCK算法的变体。

  * 简单的CLOCK置换算法：为每帧设置**一位访问位**，当某页首次被装入或被访问时，其访问位被置为1（同样由指针指向该位置来完成）。对于替换算法，将内存中的所有页面视为一个**循环队列**，并有一个替换指针与之相关联，当某一页被替换时，该指针被设置指向被替换页面的下一页。在选择一页淘汰时，只需检查页的访问位。若为0，就选择该页换出；若为1，则将它置为0，暂不换出，给予该页第二次驻留内存的机会，再依次顺序检查下一个页面。当检查到队列中的最后一个页面时，若其访问位仍为1，则返回到队首去循环检查。由于该算法是循环地检查各个页面的使用情况，故称CLOCK算法。但是，因为该算法只有一位访问位，而置换时将未使用过的页面换出，故又称**最近未用（NRU）算法**。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241007193600590.png?token=AVQM64NIKBB6HT3OPRBCBP3HFIX3S" alt="image-20241007193600590" style="zoom:67%;" />

    注意，每次替换时，是继续上一次的替换指针位置，而不是从帧1开始。

  * 改进型CLOCK置换算法：对于修改过的页面，替换代价更大。在改进型CLOCK算法中，除考虑页面使用情况外，还增加了置换代价一一**修改位**。在选择页面换出时，优先考虑**既未最近使用过又未修改过**的页面。由访问位$A$和修改位$M$可以组合成下面四种类型的页面：

    * 1类$A=0,M=0$，最佳淘汰页。
    * 2类$A=0,M=1$，不是很好的淘汰页。
    * 3类$A=1,M=0$，可能再被访问。
    * 4类$A=1,M=1$，可能再被访问。

    算法执行过程如下：

    1. 从指针的当前位置开始，扫描循环队列，寻找1类页面，将遇到的第一个1类页面作为选中的淘汰页。在第一次扫描期间**不改变访问位**。
    2. 若1失败，则进行第二轮扫描，寻找2类页面。将遇到的第一个2类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的**访问位都置0**。
    3. 若2失败，此时指针已回到开始位置，且所有帧的访问位都已复0。重复1、2步即可。

### 3.2.5 抖动和工作集

* **抖动**：频繁的页面调度行为称为**抖动**或**颠簸**。系统发生抖动的根本原因是，系统中同时运行的进程太多，由此分配给每个进程的物理块太少，不能满足进程正常运行的基本要求，致使每个进程在运行时频繁地出现缺页，必须请求系统将所缺页面调入内存。

* **工作集**：在某段时间间隔内，进程要访问的页面集合。基于局部性原理，一般用最近访问过的页面来确定工作集，即工作集$W$​可由时间$t$​和工作集窗口大小$\Delta$​来确定。例如，某进程对页面的访问次序如下：

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241008150142879.png?token=AVQM64OFFPVN5HMH4TA6CC3HFIX3U" alt="image-20241008150142879" style="zoom:67%;" />

  假设工作集窗口大小$\Delta=5$，则$t_1$时刻的工作集为$\{2,3,5\}$，$t_2$时刻的工作集为$\{1,2,3,4\}$。实际应用中，工作集窗口会设置得很大，而工作集大小一般会小很多。为了防止抖动现象，一般分配给进程的**物理块数（驻留集大小）要大于工作集大小**。

  工作集模型的原理是，让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。落在工作集内的页面需要调入驻留集中，而落在工作集外的页面可从驻留集中换出。若还有空闲物理块，则可再调一个进程到内存。若所有进程的工作集之和超过了可用物理块总数，则操作系统会暂停一个进程，将其页面调出并将物理块分配给其他进程，防止出现抖动现象。

### 3.2.6 内存映射文件

内存映射文件将**磁盘文件**的全部或部分内容与**进程虚拟地址空间**的某个区域建立**映射关系**，便可以直接访问被映射的文件，而不必执行文件I/O操作，也无须对文件内容进行缓存处理。这种特性非常适合用来**管理大尺寸文件**。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241008153739946.png?token=AVQM64IMQHVJB76RRDB4Q4LHFIX3Y" alt="image-20241008153739946" style="zoom:67%;" />

### 3.2.7 虚拟存储器性能影响因素

**缺页率**（缺页率高即为抖动）是影响虚拟存储器性能的主要因素，且缺页率又受到**页面大小**、**分配给进程的物理块数**（取决于工作集）、 **页面置换算法**以及**程序的编制方法**的影响。

* **页面大小**：页面较大则缺页率较低，页面较小则缺页率较高。页面较小时，一方面减少了内存碎片，有利于提高内存利用率；另一方面，也会使每个进程要求较多的页面，导致页表过长，占用大量内存。页面较大时，虽然可以减少页表长度，但会使页内碎片增大。 
* **分配给进程的物理块数**：分配给进程的物理块数越多，缺页率就越低，但是当物理块超过某个数目时，再为进程增加一个物理块对缺页率的改善是不明显的，只能是浪费内存空间。只要保证活跃页面在内存中，保持缺页率在一个很低的范围即可。
* **页面置换算法**：选择LRU、CLOCK等置换算法，将未来有可能访问的页面尽量保留在内存中，从而提高页面的访问速度。 
* **写回磁盘的频率**：写回磁盘的频率越低，磁盘I/O次数越少，已修改页面换出的开销越低。
* **程序的编制方法**：编写程序的局部化程度越高，执行时的缺页率就越低。

### 3.2.8 地址翻译

# 第 4 章 文件管理

## 4.1 文件系统基础

### 4.1.1 文件的基本概念

* 文件：以硬盘为载体的存储在计算机上的信息集合，文件可以是文本文档、图片、程序等。在**系统运行时**，计算机**以进程为基本单位**进行资源的调度和分配；而在**用户进行的输入、 输出中**，则**以文件为基本单位**。
* 文件系统：操作系统用于实现用户访问、修改和保存文件的文件维护管理系统。
* 文件的结构：并无严格定义。自底向上的方式：
  * 数据项：是文件系统中最低级的数据组织形式，可分为以下两种类型：
    * 基本数据项：描述一个对象的某种属性的一个值，是数据中的最小逻辑单位。
    * 组合数据项：由多个基本数据项组成。
  * 记录：一组相关的数据项的集合，用于描述一个对象在某方面的属性。
  * 文件：由创建者所定义的、具有文件名的一组相关元素的集合，可分为**有结构文件**和**无结构文件**两种。在有结构的文件中，文件由若干个相似的记录组成，如一个班的学生记录；而无结构文件则被视为一个字符流，比如一个二进制文件或字符文件。 

### 4.1.2 文件控制块和索引结点

* 文件的属性：除了文件数据，与文件相关的附加信息被称为**文件属性**或**文件元数据**。通常包括如下属性：名称、类型、创建者、所有者、位置、大小、保护、创建时间、最后一次修改时间、最后一次存取时间。操作系统通过**文件控制块（FCB）**来维护文件元数据。

* **文件控制块（FCB）**：是用来存放控制文件需要的各种信息的数据结构，以实现“按名存取”。FCB的有序集合称为**文件目录**，一个FCB就是一个**文件目录项**。为了创建一个新文件，系统将分配一个FCB并存放在文件目录中，称为目录项。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241008185724378.png?token=AVQM64PNDBME4T6RN4GBCN3HFIX32" alt="image-20241008185724378" style="zoom:67%;" />

  FCB主要包含以下信息：

  * **基本信息**：文件名、文件的物理位置、文件的逻辑结构、文件的物理结构等。 
  * **存取控制信息**：文件主的存取权限、核准用户的存取权限以及一般用户的存取权限。 
  * **使用信息**：文件建立时间、上次修改时间等。 

  一个文件目录也被视为一个文件，称为目录文件。

* **索引结点**：在检索目录的过程中，只用到了文件名，文件的其他描述信息不会用到，也不需要调入内存。因此，有的系统（如UNIX，下图）便采用了文件名和文件描述信息分开的方法，使文件描述信息单独形成一个称为**索引结点**的数据结构，简称**i结点**（inode）。在文件目录中的每个目录项仅由文件名和指向该文件所对应的i结点的指针构成。 

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241008190332586.png?token=AVQM64NGKSZOCC7AWUOD3SDHFIX36" alt="image-20241008190332586" style="zoom:67%;" />

  假设一个FCB为64B，盘块大小是1KB,则每个盘块中可以存放16个FCB （FCB**必须连续存放**），若一个文件目录共有640个FCB，则查找文件平均需要启动磁盘20次。而在UNIX系统中，一个目录项仅占16B，其中14B是文件名，2B是i结点指针。在1KB的盘块中可存放64个目录项。这样，可使查找文件的平均启动磁盘次数减少到原来的1/4，大大节省了系统开销。

  * **磁盘索引结点**：存放在磁盘上的索引结点。**每个文件有一个唯一的磁盘索引结点**，主要包括以下内容：

    * 文件主标识符。
    * 文件类型：普通文件、目录文件或特别文件。
    * 文件存取权限。
    * 文件物理地址：每个索引结点中含有13个地址项，即`iaddr(0)〜iaddr(12)`，它们以直接或间接方式给出数据文件所在盘块的编号。 
    * 文件长度。
    * 文件链接计数：本文件系统中所有指向该文件的文件名的指针计数。
    * 文件存取时间：最近被进程存取的时间、最近被修改的时间及索引结点最近被修改的时间。

  * **内存索引结点**：存放在内存中的索引结点。当文件**被打开时**，要将磁盘索引结点**复制**到内存的索引结

    点中，便于以后使用。在内存索引结点中**增加**了以下内容：

    * 索引结点编号。
    * 状态：i结点是否上锁或被修改。
    * 访问计数：每当有一进程要访问此i结点时，计数加1；**访问结束减1**。
    * 逻辑设备号：文件所属文件系统的逻辑设备号。
    * 链接指针：分别指向空闲链表和散列队列的指针。

### 4.1.3 文件的操作

* **文件的基本操作**：

  * **创建文件**：①新文件分配必要的外存空间；②在目录中为之创建一个目录项。
  * **写文件**：执行一个**系统调用**。搜索目录以查找文件位置。系统为该文件维护一个写指针，每当发生写操作时，便更新写指针。
  * **读文件**：执行一个**系统调用**。搜索目录以查找文件位置。系统为该文件维护一个读指针，每当发生读操作时，便更新读指针。一个进程通常只对一个文件读或写，因此当前操作位置可作为每个进程当前文件位置的指针，为读写共用，从而节省了空间，也降低了系统复杂度。
  * **重新定位文件**：也称**文件定位**。搜索目录以找到适当的条目，并将当前文件位置指针重新定位到给定值。重新定位文件**不涉及读、写文件**。
  * **删除文件**：先从目录中检索指定文件名的目录项，然后释放该文件所占的存储空间，以便可被其他文件重复使用，并删除目录条目。
  * **截断文件**：允许文件所有属性不变，并删除文件内容，将其长度置为0并释放其空间。

  这6个基本操作可以组合起来执行其他文件操作。例如，一个文件的复制，可以创建新文件、 从旧文件读出并写入新文件。

* **文件的打开与关闭**：

  所谓''打开”，是指调用**系统调用**open根据文件名搜索目录，将指明文件的属性（包括该文件在外存上的物理位置），从外存**复制到内存打开文件表**的一个表目中， 并将该表目的编号（也称**索引**）返回给用户。当用户再次向系统发出文件操作请求时，可通过索引在打开文件表中查到文件信息，从而节省再次搜索目录的开销。当文件不再使用时，可利用**系统调用**close关闭它，操作系统将会**从打开文件表中删除**这一条目。

  在多个不同进程可以同时打开文件的操作系统中，通常采用**两级表**：整个系统表和每个进程表。**整个系统的打开文件表**包含FCB的副本及其他信息。**每个进程的打开文件表**根据它打开的所有文件，包含指向系统表中适当条目的指针。**一旦有进程打开了一个文件，系统表就包含该文件的条目。**当另一个进程执行调用open时，只不过是在其文件打开表中**增加一个条目**，并**指向系统表**的相应条目。通常，系统打开文件表为每个文件关联一个**打开计数器**（Open Count），以记录多少进程打开了该文件。每个关闭操作close使count递减，当打开计数器**为0时**，表示该文件不再被使用，并且可从系统打开文件表中**删除相应条目**。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241008194014487.png?token=AVQM64K5KRY6EZEEQHLHGO3HFIX4A" alt="image-20241008194014487" style="zoom:67%;" />

  文件名不必是打开文件表的一部分，因为一旦完成对FCB在磁盘上的定位，系统就不再使用文件名。对于访问打开文件表的索引，UNIX称之为**文件描述符**，而Windows称之为**文件句柄**。 因此，只要文件未被关闭，所有文件操作就通过打开文件表来进行。 

  每个打开文件都具有如下关联信息： 

  * **文件指针**。系统跟踪**上次的读写位置**作为当前文件位置的指针，这种指针对打开文件的某个进程来说是唯一的，因此必须**与磁盘文件属性分开保存**。
  * **文件打开计数**。系统在删除打开文件条目之前，必须等待计数归0。
  * **文件磁盘位置**。查找磁盘上的文件所需的信息保存在内存中，以便系统不必为每个操作都从磁盘上读取该信息。
  * **访问权限**。每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等）。该信息保存在进程的打开文件表中，以便操作系统能够允许或拒绝后续的I/O请求。

### 4.1.4 文件保护

文件保护通过**口令保护**、**加密保护**和**访问控制**等方式实现。其中，口令和加密是为了防止用户文件被他人存取或窃取，而访问控制则用于控制用户对文件的访问方式。

* **访问类型**：对文件的保护可从限制对文件的访问类型中出发。可加以控制的访问类型主要有以下几种。

  * **读**。
  * **写**。
  * **执行**：将文件装入内存并执行。
  * **添加**：将新信息添加到文件结尾部分。
  * **删除**。
  * **列表清单**：列出文件名和文件属性。

  此外还可以对文件的**重命名**、**复制**、**编辑**等加以控制。这些高层的功能可以通过系统程序调用低层系统调用来实现。**保护可以只在低层提供**。例如，复制文件可利用一系列的读请求来完成，这样，具有读访问权限的用户同时也就具有了复制和打印权限。

* **访问控制**：解决访问控制最常用的方法是根据用户身份进行控制。而实现基于身份访问的最为普通的方法是，为每个文件和目录增加一个**访问控制列表**（Access-Control List, **ACL**），以规定**每个用户名**及其所允许的访问类型。这种方法的优点是可以使用复杂的访问方法，缺点是长度无法预计并且可能导致复杂的空间管理，使用**精简的访问列表**可以解决这个问题。

  精简的访问列表采用拥有者、组和其他三种用户类型。

  * **拥有者**。创建文件的用户。
  * **组**。一组需要共享文件且具有类似访问的用户。
  * **其他**。系统内的所有其他用户。 

  这样，只需用三个域即可列出访问表中这三类用户的访问权限。文件主在创建文件时，说明创建者用户名及所在的组名，系统在创建文件时也将文件主的名字、所属组名列在该文件的FCB中。用户访问该文件时，若用户是文件主，按照文件主所拥有的权限访问文件；若用户和文件主在同一个用户组，则按照同组权限访问，否则只能按其他用户权限访问。

* **口令保护和加密保护**：口令和密码是另外两种访问控制方法。

  **口令**指用户在建立一个文件时提供一个口令，系统为其建立FCB时附上相应口令，同时告诉允许共享该文件的其他用户。用户请求**访问时**必须**提供相应的口令**。这种方法时间和空间的开销不多，缺点是口令**直接存在系统内部**，不够安全。 

  **密码**指用户对文件进行**加密**，文件被访问时需要使用**密钥**。这种方法保密性强，节省了存储空间，不过编码和译码要花费一定的时间。 口令和密码都是防止用户文件被他人存取或窃取，并没有控制用户对文件的访问类型。 

现代操作系统常用的文件保护方法是，将访问控制列表与用户、组和其他成员访问控制方案一起**组合使用**。

对于多级目录结构而言，不仅需要保护单个文件，而且需要保护子目录内的文件，即需要提供**目录保护机制**。目录操作与文件操作并不相同，因此需要不同的保护机制。

### 4.1.5 文件的逻辑结构

文件的**逻辑结构**是从**用户观点出发**看到的文件的组织形式。文件的**物理结构**（又称文件的**存储结构**）是从**实现观点出发**看到的文件在外存上的存储组织形式。文件的逻辑结构与存储介质特性无关，它实际上是指在文件的内部，数据逻辑上是如何组织起来的。 

按逻辑结构，文件可划分为**无结构文件**和**有结构文件**两大类。

* **无结构文件**：也称**流式文件**，是**最简单**的文件组织形式。无结构文件将数据按顺序组织成记录并积累、保存， 它是有序相关信息项的集合，**以字节为单位**。由于无结构文件没有结构，因而对记录的**访问只能通过穷举搜索**的方式，因此这种文件形式**对大多数应用不适用**。但字符流的无结构文件管理简单，用户可以方便地对其进行操作。所以，那些**对基本信息单位操作不多的文件**较适于采用字符流的无结构方式，如*源程序文件、目标代码文件*等。

* **有结构文件**：也称**记录式文件**。按记录的组织形式可以分为以下几种：

  * **顺序文件**：文件中的记录一个接一个地顺序排列，记录通常是**定长**的，可以顺序存储或以链表形式存储。 顺序文件有以下两种结构：第一种是**串结构**，记录之间的顺序与关键字无关，通常是按**存入时间的先后**进行排列，对串结构文件进行检索**必须从头开始**顺序依次查找，比较费时。第二种是**顺序结构**，指文件中的所有记录按**关键字顺序**排列，可采用**折半查找法**，提高了检索效率。 

    在对记录进行**批量操作**，即每次要读或写一大批记录时，顺序文件的**效率**是所有逻辑文件中**最高**的。此外，对于**顺序存储设备**（如磁带），也只有顺序文件才能被存储并能有效地工作。在经常需要查找、修改、增加或删除**单个记录**的场合，顺序文件的**性能较差**。

  * **索引文件**：变长记录文件只能顺序查找，效率较低。为此，可以建立一张索引表，为主文件的每个记录在索引表中分别设置一个表项，包含指向变长记录的**指针**（即逻辑起始地址）和**记录长度**，索引表**按关键字排序**，因此其*本身也是一个定长记录的顺序文件*。这样就把对变长记录顺序文件的检索转变为对定长记录索引文件的随机检索，从而加快了记录的检索速度。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009144223739.png?token=AVQM64LYLSGBMRKFYOIVXH3HFIX4E" alt="image-20241009144223739" style="zoom:67%;" />

  * **索引顺序文件**：顺序文件和索引文件的结合。索引顺序文件将顺序文件中的所有记录**分为若干组**，为顺序文件建立一张索引表，在索引表中为**每组中的第一条记录建立一个索引项**，其中含有该记录的关键字值和指向该记录的指针。查找一条记录时，首先通过索引表找到其所在的组，然后在该组中使用顺序查找，就能很快地找到记录。

    对于含有$N$条记录的顺序文件，查找某关键字的记录时，平均需要查找$(N+1)/2$次。在索引顺序文件中，假设$N$条记录分为$\sqrt{N}$组，索引表中有$\sqrt{N}$个表项，每组有$\sqrt{N}$条记录，在查找某关键字的记录时，平均需要查找$(\sqrt{N}+1)/2+(\sqrt{N}+1)/2=\sqrt{N}+1$次。因此，索引顺序文件提高了查找效率，这种查找方式就是数据结构中的分块查找。

  * **直接文件**或**散列文件（哈希文件）**：给定记录的键值或通过哈希函数转换的键值直接决定记录的物理地址。这种映射结构不同于顺序文件或索引文件，没有顺序的特性。 *散列文件有很高的存取速度，但是会引起冲突*，即不同关键字的散列函数值相同。 

### 4.1.6 文件的物理结构

文件的物理结构就是研究文件的实现，即文件数据在物理存储设备上是如何分布和组织的。同一个问题有两个方面的回答：一是文件的**分配方式**，讲的是对磁盘**非空闲块**的管理；二是文件**存储空间管理**，讲的是对磁盘**空闲块**的管理（4.3节）。 

文件分配对应于文件的物理结构，是指如何为文件分配磁盘块。常用的磁盘空间分配方法有三种：**连续分配**、**链接分配**和**索引分配**。有的系统（如RDOS操作系统）对三种方法都支持，但更普遍的是一个系统只支持一种方法。

* **连续分配**：每个文件在磁盘上占有一组连续的块。磁盘地址定义了磁盘上的一个线性排序，这种排序使作业访问磁盘时需要的**寻道数和寻道时间最小**。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009151638554.png?token=AVQM64M7INVXEKAY57FI6TTHFIX4G" alt="image-20241009151638554" style="zoom:67%;" />

  一个文件的目录项中“文件物理地址”字段应包括第一块的地址和该文件所分配区域的长度，若文件长n块并从位置b开始，则该文件将占有块b, b+1, b + 2, ..., b + n。

  连续分配支持**顺序访问**和**直接访问**。

  * **优点**：实现简单、存取速度快。
  * **缺点**：①文件长度不宜动态增加，因为一个文件末尾后的盘块可能已分配给其他文件，一旦需要增加，就需要大量移动盘块。②为保持文件的有序性，删除和插入记录时，需要对相邻的记录做物理上的移动，还会动态改变文件的长度。③反复增删文件后会产生**外部碎片**(与内存管理分配方式中的碎片相似)。 ④很难确定一个文件需要的空间大小，因而**只适用于长度固定的文件**。

* **链接分配**：离散分配的方式。消除了磁盘的外部碎片，提高了磁盘的利用率。可以动态地为文件分配盘块，因此无须事先知道文件的大小。此外，对文件的插入、删除和修改也非常方便。链接分配又可分为隐式链接和显式链接两种形式。

  * **隐式链接**：目录项中含有文件第一块的指针和最后一块的指针。每个文件对应一个磁盘块的链表；磁盘块分布在磁盘的任何地方，除最后一个盘块外，每个盘块都含有指向文件下一个盘块的指针，这些指针对用户是透明的。

    缺点是**只适合顺序访问**，随机访问（直接存取）效率很低。稳定性低，链表中的指针丢失或损坏，会导致文件数据的丢失。 

    通常的解决方案是，将几个盘块组成**簇（cluster）**，按簇而不按块来分配，可以成倍地**减少查找时间**。比如一簇为4块，这样，指针所占的磁盘空间比例也要小得多。这种方法的代价是**增加了内部碎片**。簇可以改善许多算法的磁盘访问时间，因此应用于大多数操作系统。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009152522093.png?token=AVQM64IJN45E26BWYBAWZQLHFIX4K" alt="image-20241009152522093" style="zoom:67%;" />

  * **显式链接**：把链接文件各物理块的指针，从每个物理块的末尾中提取出来，显式地存放在内存的一张链接表中。该表在整个磁盘中仅设置一张，称为**文件分配表**（File Allocation Table, **FAT**）。每个表项中存放链接指针，即下一个盘块号。文件的第一个盘块号记录在目录项“物理地址”字段中，后续的盘块可通过查FAT找到。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009152822844.png?token=AVQM64JVERIQXJF3DD3PDJLHFIX4M" alt="image-20241009152822844" style="zoom:67%;" />

    -1表示文件的最后一块，可以用-2表示这个磁盘块是空闲的（当然也可指定为-3, -4）。因此，FAT不仅记录了文件各块之间的先后链接关系，同时还标记了空闲的磁盘块， 操作系统也可以通过FAT对文件存储空间进行管理。 当某进程请求操作系统分配一个磁盘块时，操作系统只需从FAT中找到-2的表项，并将对应的磁盘块分配给进程即可。

    FAT表在系统启动时就会被读入内存，因此查找记录的过程是在**内存中进行**的，因而不仅显著地提高了检索速度，而且明显减少了访问磁盘的次数。

* **索引分配**：链接分配解决了连续分配的外部碎片和文件大小管理的问题。但依然存在问题：①链接分配不能有效支持直接访问（FAT除外）；②FAT需要占用较大的内存空间。事实上，在打开某个文件时，只需*将该文件对应盘块的编号调入内存*即可，完全没有必要将整个FAT调入内存。为此，索引分配将每个文件所有的盘块号都集中放在一起构成**索引块（表）**。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009153719278.png?token=AVQM64NJX5EIQ3WARJQTZMLHFIX4Q" alt="image-20241009153719278" style="zoom:67%;" />

  索引分配的优点是支持直接访问，且没有外部碎片问题。缺点是由于索引块的分配，增加了系统存储空间的开销。索引块的大小是一个重要的问题，每个文件必须有一个索引块，因此索引块应尽可能小，但索引块太小就无法支持大文件。可以采用以下机制来处理这个问题。

  * **链接方案**。一个索引块通常为一个磁盘块，因此它本身能直接读写。为了支持大文件，可以将**多个索引块链接**起来。 
  * **多层索引**。通过第一级索引块指向一组第二级的索引块，第二级索引块再指向文件块。查找时，通过第一级索引查找第二级索引，再采用这个第二级索引查找所需数据块。这种方法根据最大文件大小，可以继续到第三级或第四级。
  * **混合索引**。将多种索引分配方式相结合的分配方式。例如，系统既采用直接地址，又采用单级索引分配方式或两级索引分配方式。 

  此外，访问文件需两次访问外存，先读取索引块的内容，然后访问具体的磁盘块，因而降低了文件的存取速度。为了解决这一问题，通常将文件的索引块读入内存，以提高访问速度。

* **混合索引分配**：对于**小文件**，为了提高对众多小文件的访问速度，最好能将它们的每个盘块地址直接放入FCB,这样就可以直接从FCB中获得该文件的盘块地址，即为**直接寻址**。对于**中型文件**，可以采用**单级索引**方式，需要先从FCB中找到该文件的索引表，从中获得该文件的盘块地址，即为一次间址。对于**大型或特大型文件**，可以采用**多级索引**分配方式。UNIX系统采用的就是这种分配方式， 在其索引结点中，共设有13个地址项，即i.addr(0)〜i.addr(12)。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009154410540.png?token=AVQM64MRQAV4Z3VGKCACCQTHFIX4S" alt="image-20241009154410540" style="zoom: 50%;" />

  * **直接地址**：i.addr(0)〜i.addr(9)存放直接地址，即文件数据盘块的盘块号。
  * **一次间接地址**：i.addr(10)提供一次间接地址。在一次间接地址块中可存放1024个盘块号。
  * **多次间接地址**：当文件长度大于一次间接地址+10个直接地址能提供的大小时，i.addr(11)提供二次间接地址，i.addr(12)提供三次间接地址。

## 4.2 目录

### 4.2.1 目录的基本概念

* **目录的基本概念**：FCB的有序集合称为**文件目录**，一个FCB就是一个文件目录项。与文件管理系统和文件集合相关联的是文件目录，它包含有关文件的属性、位置和所有权等。
* 目录管理的基本要求：实现“按名存取”；提高目录检索速度；提供控制访问信息；允许不同用户对不同文件采用相同名字。

### 4.2.2 目录结构

* **单级目录结构**：在整个文件系统中只建立一张目录表，每个文件占一个目录项。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009183515842.png?token=AVQM64NEBQNIH3SKITDVSI3HFIX4W" alt="image-20241009183515842" style="zoom:67%;" />

  当访问一个文件时，先按文件名在该目录中查找到相应的FCB，经合法性检查后执行相应的操作。当建立一个新文件时，必须先检索所有目录项，以**确保没有“重名”**的情况，然后在该目录中增设一项，把新文件的属性信息填入到该项中。当删除一个文件时，先从该目录中找到该文件的目录项，回收该文件所占用的存储空间，然后清除该目录项。 

  单级目录结构实现了 “按名存取”，但是存在查找速度慢、文件不允许重名、不便于文件共享等缺点，而且对于**多用户的操作系统**显然是**不适用**的。

* **两级目录结构**：为了克服单级目录所存在的缺点，可以采用两级方案，将文件目录分成**主文件目录**（MasterFile Directory, **MFD**）和**用户文件目录**（UserFile Directory, **UFD**）两级。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009185332768.png?token=AVQM64JPABLNOGDZZTZEIHLHFIX4Y" alt="image-20241009185332768" style="zoom:67%;" />

  主文件目录项记录用户名及相应用户文件目录所在的存储位置。用户文件目录项记录该用户文件的FCB信息。当某用户欲对其文件进行访问时，只需搜索该用户对应的UFD，这既解决了不同用户文件的“重名”问题，又在一定程度上保证了文件的安全。 

  两级目录结构提高了检索的速度，解决了多用户之间的文件重名问题，文件系统可以在目录上实现访问限制。但是两级目录结构缺乏灵活性，**不能对文件分类**。

* **树形目录结构**：将两级目录结构加以推广，就形成了树形目录结构。它可以明显地提高对目录的检索速度和文件系统的性能。当用户要访问某个文件时，用文件的路径名标识文件，文件路径名是个字符串，由从根目录出发到所找文件通路上所有目录名与数据文件名用分隔符“/”链接而成。从根目录出发的路径称为**绝对路径**。当层次较多时，每次从根目录查询会浪费时间，于是加入了**当前目录**（又称**工作目录**），进程对各文件的访问都是相对于当前目录进行的。当用户要访问某个文件时，使用**相对路径**标识文件，相对路径由从当前目录出发到所找文件通路上所有目录名与数据文件名用分隔符"/”链接而成。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009190732957.png?token=AVQM64IFVRXQ2Q7OS4KFJO3HFIX44" alt="image-20241009190732957" style="zoom:67%;" />

  树形目录结构可以很方便地对文件进行分类，层次结构清晰，也能够更有效地进行文件的管理和保护。在树形目录中，不同性质、不同用户的文件，可以分别呈现在系统目录树的不同层次或不同子树中，很容易地赋予不同的存取权限。但是，在树形目录中查找一个文件，需要**按路径名逐级访问**中间结点，增加了磁盘访问次数，这无疑会**影响查询速度**。目前，大多数操作系统如UNIX、Linux和Windows系统都采用了树形文件目录。

* **无环图目录结构**：树形目录结构能便于实现文件分类，但不便于实现文件共享，为此在树形目录结构的基础上增加了一些指向同一结点的有向边，使整个目录成为一个有向无环图。

  当某用户要求删除一个共享结点时，若系统只是简单地将它删除，则当另一共享用户需要访问时，会因无法找到这个文件而发生错误。为此，可为每个共享结点设置一个**共享计数器**，每当图中增加对该结点的共享链时，计数器加1；每当某用户提出删除该结点时，计数器减1。仅当共享计数器为0时，才真正删除该结点，否则仅删除请求用户的共享链。 

  共享文件（或目录）**不同于文件拷贝**（副本）。若有两个文件拷贝，则每个程序员看到的是拷贝而不是原件；然而，若一个文件被修改，则另一个程序员的拷贝不会改变。对于共享文件，**只存在一个真正的文件**，任何改变都会为其他用户所见。 

  无环图目录结构方便地实现了文件的共享，但使得系统的管理变得更加复杂。

### 4.2.3 目录的操作

目录层次上执行的操作有：搜索、创建文件、删除文件、创建目录、删除目录、移动目录、显示目录、修改目录。

### 4.2.4 目录实现*

目录实现的基本方法有线性列表和哈希表两种，要注意目录的实现就是为了查找， 因此线性列表实现对应线性查找，哈希表的实现对应散列查找。

* **线性列表**：最简单的目录实现方法是，采用文件名和数据块指针的线性列表。当创建新文件时，必须首先搜索目录以确定没有同名的文件存在，然后在目录中增加一个新的目录项。当删除文件时，则根据给定的文件名搜索目录，然后释放分配给它的空间。当要重用目录项时有许多种方法：可以将目录项标记为不再使用，或将它加到空闲目录项的列表上，还可以将目录的最后一个目录项复制到空闲位置，并减少目录的长度。

  采用链表结构可以减少删除文件的时间。 线性列表的优点在于实现简单，不过由于线性表的特殊性，查找比较费时。

* **哈希表**：哈希表根据文件名得到一个值，并返回一个指向线性列表中元素的指针。这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些措施来避免冲突（两个文件名称哈希到同一位置）。 

  目录查询是通过在磁盘上反复搜索完成的，需要不断地进行I/O操作，开销较大。所以如前所述，为了减少I/O操作，**把当前使用的文件目录复制到内存**，以后要使用该文件时只需在内存中操作，因此降低了磁盘操作次数，提高了系统速度。

### 4.2.5 文件共享

文件共享使多个用户共享同一个文件，系统中只需保留该文件的一个副本。现代常用的两种文件共享方法如下。

* **基于索引结点的共享方式（硬链接）**：在树形结构的目录中，当有两个或多个用户要共享一个子目录或文件时，必须将共享文件或子目录链接到两个或多个用户的目录中，才能方便地找到该文件。 在这种共享方式中，诸如文件的物理地址及**其他的文件属性**等信息，不再放在目录项中，而**放在索引结点中**。**在文件目录中只设置文件名及指向相应索引结点的指针**。在索引结点中还应有一个**链接计数**count,用于表示链接到本索引结点（即文件）上的用户目录项的数目。当count = 2时，表示有两个用户目录项链接到本文件上，或者说有两个用户共享此文件。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009202401076.png?token=AVQM64LNCVYE33T3XZSKX3LHFIX46" alt="image-20241009202401076" style="zoom:67%;" />

  用户A创建一个新文件时，他就成为了文件的所有者。假如用户B共享了此文件，用户A不再需要该文件时，用户A删除自己目录中的相应目录项，但无法删除索引结点，因为此时计数为1。用户A删除目录项不会改变文件的所有者。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241009211748451.png?token=AVQM64IJFMZQISAVYLJEM73HFIX5C" alt="image-20241009211748451" style="zoom:67%;" />

* **利用符号链实现文件共享（软链接）**：为使用户B能共享用户A的一个文件F，可以由系统创建一个**LINK类型**的新文件，也取名为F，并将该文件写入用户B的目录中，以实现用户B的目录与文件F的链接。在新文件中只包含被链接文件F的**路径名**。当用户B要访问被链接的文件F且正要读LINK类新文件时，操作系统查看到要读的文件是LINK类型，则根据该文件中的路径名去找到文件F，然后对它进行读， 从而实现用户B对文件F的共享。这样的链接方法被称为**符号链接**。 

  在利用符号链方式实现文件共享时，只有文件主才拥有指向其索引结点的指针。而共享该文件的其他用户只有该文件的路径名，并不拥有指向其索引结点的指针。这样，也就不会发生在文件主删除一共享文件后留下一悬空指针的情况。当文件主把一个共享文件删除后，若其他用户又试图通过符号链去访问它时，则会访问失败，于是将符号链删除，此时不会产生任何影响。 

  在符号链的共享方式中，当其他用户读共享文件时，系统根据文件路径名逐个查找目录，直至找到该文件的索引结点。因此，每次访问共享文件时，都可能要**多次读盘**。使得访问文件的开销甚大，且增加了启动磁盘的频率。此外，符号链的索引结点也要**耗费磁盘空间**。 

  利用符号链实现网络文件共享时，只需提供该文件所在机器的网络地址及文件路径名。 硬链接和软链接都是文件系统中的**静态共享方法**，在文件系统中还存在着另外的共享需求， 即两个进程**同时对同一个文件进行操作**，这样的共享称为**动态共享**。

**硬链接的查找速度要比软链接的快**。 

## 4.3 文件系统

### 4.3.1 文件系统结构

文件系统（File system）提供高效和便捷的磁盘访问，以便允许存储、定位、提取数据。文件系统有两个设计问题：定义文件系统的用户接口；创建算法和数据结构，以便映射逻辑文件系统到物理外存设备。现代操作系统有多种文件系统类型，因此文件系统的层次结构也不尽相同。下图是一个合理的文件系统层次结构。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010140645483.png?token=AVQM64MAEKMQL5KYM5YDDRDHFIX5E" alt="image-20241010140645483" style="zoom:67%;" />

* **I/O控制**：包括设备驱动程序和中断处理程序，在内存和磁盘系统之间传输信息。设备驱动程序将输入的命令翻译成底层硬件的特定指令，硬件控制器利用这些指令使I/O设备与系统交互。
* **基本文件系统**：向对应的设备驱动程序发送通用命令，以读写磁盘的物理块。每个物理块由磁盘地址标识。该层也管理内存缓冲区，并保存各种文件系统、目录和数据块的缓存。在进行磁盘块传输前，分配合适的缓冲区，并对缓冲区进行管理。
* **文件组织模块**：组织文件及其逻辑块和物理块。将逻辑块地址转换成物理块地址。文件组织模块还包括空闲空间管理器，以跟踪未分配的块，根据需求提供给文件组织模块。
* **逻辑文件系统**：用于管理元数据信息。元数据包括文件系统的所有结构，而不包括实际数据。通过文件控制块来维护文件结构。逻辑文件系统还负责文件保护。

### 4.3.2 文件系统布局

* **文件系统在磁盘中的结构**：文件系统存放在磁盘上，多数磁盘划分为一个或多个分区，每个分区中有一个独立的文件系统。文件系统可能包括如下信息：启动存储在那里的操作系统的方式、总的块数、空闲块的数量和位置、目录结构以及各个具体文件等。下图为一个可能的文件系统布局。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010144313197.png?token=AVQM64IRAXBY5GYVISOGU6DHFIX5G" alt="image-20241010144313197" style="zoom:67%;" />

  * **主引导记录（MBR）**：位于磁盘的0号扇区，用来引导计算机，MBR后面是分区表，该表给出每个分区的起始和结束地址。表中的一个分区被标记为**活动分区**，当计算机启动时，BIOS读入并执行MBR。MBR做的第一件事是确定活动分区，读入它的第一块，即**引导块**。
  * **引导块（Boot Block）**：MBR执行引导块中的程序后，该程序负责启动该分区中的操作系统。为统一起见，**每个分区都从一个引导块开始**，即使它不含有一个可启动的操作系统，也不排除以后会在该分区安装一个操作系统。Windows系统称之为**分区引导扇区**。 除了从引导块开始，磁盘分区的布局是随着文件系统的不同而变化的。
  * **超级块（Super Block）**：包含文件系统的所有关键信息，在计算机启动时，或者在该文件系统首次使用时，超级块会被读入内存。超级块中的典型信息包括分区的块的数量、块的大小、空闲块的数量和指针、空闲的FCB数量和FCB指针等。

* **文件系统在内存中的结构**：内存中的信息用于管理文件系统并通过缓存来提高性能。这些数据在安装文件系统时被加载，在文件系统操作期间被更新，在卸载时被丢弃。这些结构的类型可能包括：

  * 内存中的**安装表（mounttable）**，包含每个己安装文件系统分区的有关信息。
  * 内存中的**目录结构的缓存**，包含最近访问目录的信息。对安装分区的目录，它可以包括一个指向分区表的指针。
  * **整个系统的打开文件表**，包含每个打开文件的FCB副本及其他信息。
  * **每个进程的打开文件表**，包含一个指向整个系统的打开文件表中的适当条目的指针，以及其他信息。

### 4.3.3 外存空闲管理

一个存储设备可以按整体用于文件系统，也可以细分。例如，一个磁盘可以划分为4个分区， 每个分区都可以有单独的文件系统。**包含文件系统的分区**通常称为**卷（volume）**。卷可以是磁盘的一部分，也可以是整个磁盘，还可以是**多个磁盘组成RAID集**。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010151611252.png?token=AVQM64MB2VGXV4GWECRDUMTHFIX5K" alt="image-20241010151611252" style="zoom:67%;" />

在一个卷中，存放文件数据的空间（文件区）和FCB的空间（目录区）是分离的。由于存在很多种类的文件表示和存放格式，所以现代操作系统中一般都有很多不同的文件管理模块，通过它们可以访问不同格式的卷中的文件。卷在提供文件服务前，必须由对应的文件程序进行初始化，划分好目录区和文件区，建立空闲空间管理表格及存放卷信息的超级块。 文件存储设备分成许多**大小相同**的物理块，并以块为单位交换信息，因此，文件存储设备的管理实质上是对空闲块的组织和管理，它包括空闲块的组织、分配与回收等问题。

* **空闲表法**：属于**连续分配方式**，它与内存的动态分配方式类似，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲表，每个空闲区对应一个空闲表项，其中包括表项序号、该空闲区的第一个盘块号、该区的空闲盘块数等信息。再将所空闲区按其起始盘块号递增的次序排列。

  空闲盘区的分配与内存的动态分配类似，同样采用首次适应算法和最佳适应算法等。系统在对用户所释放的存储空间进行回收时，也采取类似于内存回收的方法，即要考虑回收区是否与空闲盘块表中插入点的前区和后区相邻接，对相邻接者应予以合并。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010152717014.png?token=AVQM64JHZZLHBASAAI6YPNLHFIX5M" alt="image-20241010152717014" style="zoom:67%;" />

* **空闲链表法**：将所有空闲盘区拉成一条空闲链。根据构成链所用基本元素的不同，分为两种形式：

  * 空闲盘块链：以盘块为单位拉成一条链。用户创建文件请求分配存储空间时，从链首开始取空闲块；用户删除文件释放存储空间时，从链尾插入回收的盘块。
    * 优点：分配和回收过程简单。
    * 缺点：为一个文件分配盘块时可能要重复操作多次，效率较低。以盘块为单位，链很长。
  * 空闲盘区链：以盘区为单位拉成一条链。每个盘区除含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小（盘块数）的信息。分配盘区的方法与内存的动态分区分配类似，通常采用**首次适应算法**。
    * 优点：效率高。链较短。
    * 缺点：分配和回收过程复杂。
    * 空闲表法和空闲链表法都**不适用于大型文件系统**，因为这会使空闲表或空闲链表太大。

* **位示图法**：利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。当其值为"0”时，表示对应的盘块空闲；为“1”时，表示已分配。这样， 一个$m\times n$位组成的位示图就可用来表示$m\times n$个盘块的使用情况。

* **成组链接法**：UNIX系统采用的方法。这种方法结合了空闲表和空闲链表两种方法，它具有上述两种方法的优点，克服了两种方法均有的表太长的缺点。 

  用来存放一组空闲盘块号（空闲盘块的块号）的盘块称为**成组链块**。成组链接法的大致思想是：把顺序的n个空闲盘块号保存在第一个成组链块中，其最后一个空闲盘块（作为成组链块）则用于保存另一组空闲盘块号，如此继续，直至所有空闲盘块均予以链接。系统只需保存指向第一个成组链块的指针。假设磁盘最初全为空闲盘块，其成组链接如图所示。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010154220368.png?token=AVQM64I2HL43C7UEIWLT72THFIX5Q" alt="image-20241010154220368" style="zoom:67%;" />

  分配盘块后，指针下移；回收盘块后，指针上移。

  表示空闲空间的位向量表或第一个成组链块，以及卷中的目录区、文件区划分信息都要存放在磁盘中，一般放在卷头位置，在UNIX系统中称为**超级块**。在对卷中的文件进行操作前，超级块需要预先读入系统空闲的主存，并且经常保持主存超级块与磁盘卷中超级块的一致性。

### 4.3.4 虚拟文件系统

**虚拟文件系统（VFS）**为用户程序提供了文件系统操作的统一接口，屏蔽了不同文件系统的差异和操作细节。用户程序可以通过VFS提供的统一调用函数（如open等）来操作不同文件系统（如ext3等）的文件，而无须考虑具体的文件系统和实际的存储介质。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010154808273.png?token=AVQM64JMWGLS5L7SDFB7JETHFIX5U" alt="image-20241010154808273" style="zoom:67%;" />

虚拟文件系统采用了面向对象的思想，它抽象出一个通用的文件系统模型，定义了通用文件系统都支持的接口。新的文件系统只要支持并实现这些接口，即可安装和使用。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010154907096.png?token=AVQM64MRRMFNWOGPS6PEC4LHFIX5Y" alt="image-20241010154907096" style="zoom:67%;" />

为了实现VFS，Linux主要抽象了四种对象类型。每个VFS对象都存放在一个适当的数据结构中，其中包括对象的属性和指向对象方法（函数）表的指针。

* **超级块对象**：操作方法（函数）指针指向该超级块的操作方法表，包含一系列可在超级块对象上调用的操作函数， 主要有分配inode、销毁inode、读inode、写inode、文件同步等。

* **索引结点对象**：索引结点对象提供许多操作接口，如创建新索引结点、创建硬链接、创建新目录等。

* **目录项对象**：目录项对象包含指向关联索引结点的指针，还包含指向父目录和指向子目录的指针。不同于前面两个对象，目录项对象在磁盘上没有对应的数据结构，而是VFS在遍历路径的过程中，将它们逐个解析成目录项对象的。

* **文件对象**：表示一个与进程相关的**已打开文件**。由于多个进程可以打和操作同一文件，所以同一文件在内存中可能存在多个对应的文件对象，但对应的索引结点和目录项是唯一的。文件对象包含与该文件相关联的目录项对象，包含该文件的文件系统、文件指针等，还包含在该文件对象上调用的一系列操作函数。 

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010160238121.png?token=AVQM64LFM3X34Z53IDXEE7THFIX54" alt="image-20241010160238121" style="zoom:67%;" />

VSF还有另一个重要作用，即提高系统性能。*最近最常使用的目录项对象被放在目录项高速缓存的磁盘缓存中*，以加速从文件路径名到最后一个路径分量的索引结点的转换过程。 

严格来说，VFS并不是一种实际的文件系统，它**只存在于内存中**，不存在于任何外存空间中。VFS在系统启动时建立，在系统关闭时消亡。

### 4.3.5 分区和安装

一个磁盘可以划分为多个分区，每个分区都可以用于创建单独的文件系统，每个分区还可以包含不同的操作系统。分区可以是原始的，没有文件系统。

如文件在使用前必须打开一样，文件系统在进程使用前必须先**安装**，也称**挂载**。

在启动时，Windows操作系统自动发现所有设备，并且安装所有找到的文件系统。

# 第 5 章 I/O管理

## 5.1 I/O管理概述

### 5.1.1 I/O设备

* **设备的分类**：

  * 按**信息交换的单位**分类，I/O设备可分为：
    * **块设备**。信息交换以数据块为单位。它属于**有结构设备**，如磁盘等。磁盘设备的基本特征是传输速率较高、可寻址，即对它可随机地读/写任意一块。
    * **字符设备**。信息交换以字符为单位。它属于**无结构类型**，如交互式终端机、打印机等。 它们的基本特征是传输速率低、不可寻址，并且时常采用中断I/O方式。
  * 按**传输速率**分类，I/O设备可分为：
    * **低速设备**。传输速率仅为每秒几字节到数百字节的一类设备，如键盘、鼠标等。
    * **中速设备**。传输速率为每秒数千字节至数万字节的一类设备，如激光打印机等。
    * **高速设备**。传输速率在数百千字节至千兆字节的一类设备，如磁盘机、光盘机等。

* **I/O接口**：I/O接口（**设备控制器**）位于CPU与设备之间，它既要与CPU通信，又要与设备通信，还要具有按CPU发来的命令去控制设备工作的功能，主要由三部分组成。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010180124380.png?token=AVQM64IBSBFGPPPJYJZ72RLHFIX6A" alt="image-20241010180124380" style="zoom:67%;" />

  * **设备控制器与CPU的接口**：该接口有三类信号线：**数据线**、**地址线**和**控制线**。数据线通常与两类寄存器相连：**数据寄存器**（存放从设备送来的输入数据或从CPU送来的输出数据）和**控制/状态寄存器**（存放从CPU送来的控制信息或设备的状态信息）。
  * **设备控制器与设备的接口**：一个设备控制器可以连接一个或多个设备，因此控制器中有一个或多个设备接口。每个接口中都存在**数据**、**控制**和**状态**三种类型的信号。
  * **I/O逻辑**：用于实现对设备的控制。它通过一组控制线与CPU交互，对从CPU收到的I/O命令进行译码。CPU启动设备时，将启动命令发送给控制器，同时通过地址线把地址发送给控制器，由控制器的I/O逻辑对地址进行译码，并相应地对所选设备进行控制。

  设备控制器的主要功能有：①接收和识别CPU发来的命令；②数据交换（设备和控制器之间、控制器和主存之间）；③标识和报告设备的状态，以供CPU处理；④地址识别；⑤数据缓冲；⑥差错控制。

* **I/O端口**：设备控制器中可被CPU**直接访问**的寄存器，主要有以下三类寄存器。

  * **数据寄存器**：实现CPU和外设之间的数据缓冲。 
  * **状态寄存器**：获取执行结果和设备的状态信息， 以让CPU知道是否准备好。
  * **控制寄存器**：由CPU写入，以便启动命令或更改设备模式。

  为了实现CPU和I/O端口通信，有两种方法。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010181525636.png?token=AVQM64IRJC2DMUAQSVDMKXTHFIX6C" alt="image-20241010181525636" style="zoom:67%;" />

  * **独立编址**。为每个端口分配一个I/O端口号，所有I/O端口形成I/O端口空间，*普通用户程序不能对其进行访问，只有操作系统使用特殊的I/O指令才能访问端口*。
  * **统一编址**。又称**内存映射I/O**，每个端口被分配唯一的内存地址，且不会有内存被分配这一地址，通常分配给端口的地址靠近地址空间的顶端。

### 5.1.2 I/O控制方式

外围设备和内存之间的输入/输出控制方式有4种。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010182256654.png?token=AVQM64LXT6RE7B4T3I4K6R3HFIX6G" alt="image-20241010182256654" style="zoom:67%;" />

* **程序直接控制方式**：计算机从外部设备读取的每个字，CPU需要对外设状态进行**循环检查**，直到确定该字己经在I/O控制器的数据寄存器中。在程序直接控制方式中，由于CPU的高速性和I/O设备的低速性，致使CPU的绝大部分时间都处于等待I/O设备完成数据I/O的循环测试中，造成了CPU资源的极大浪费。在该方式中，CPU之所以要不断地测试I/O设备的状态，就是因为在CPU中**未采用中断机构**，使I/O设备无法向CPU报告它已完成了一个字符的输入操作。

  程序直接控制方式简单且易于实现，但CPU和I/O设备是**串行**工作的，CPU的利用率相当低。

* **中断驱动方式**：允许I/O设备发出**中断信号**主动打断CPU的运行并请求服务，从而"解放” CPU，使得其向I/O控制器发送读命令后可以继续做其他有用的工作。

  中断驱动方式比程序直接控制方式有效，但由于数据中的每个字在存储器与I/O控制器之间的传输都必须经过CPU，这就导致了中断驱动方式仍然会消耗较多的CPU时间。

* **DMA方式**：DMA （**直接存储器存取**）方式的基本思想是在I/O设备和内存之间开辟**直接**的数据交换通路，彻底"解放” CPU。DMA方式的特点如下：

  * 基本单位是**数据块**。

  * 数据直接地在设备和内存之间（双向）传输。

  * 仅在传送一个或多个数据块的开始和结束时，才需CPU干预，整块数据的传送是在DMA控制器的控制下完成的。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010185155995.png?token=AVQM64I4BR4ZFYKXLIXQ7I3HFIX6K" alt="image-20241010185155995" style="zoom:67%;" />

  要在主机与控制器之间实现成块数据的直接交换，须在DMA控制器中设置如下4类寄存器：

  * **命令/状态寄存器（CR）**：接收从CPU发来的I/O命令、有关控制信息，或设备的状态。
  * **内存地址寄存器（MAR）**：在输入时，它存放把数据从设备传送到内存的起始目标地址；在输出时，它存放由内存到设备的内存源地址。
  * **数据寄存器（DR）**：暂存从设备到内存或从内存到设备的数据。
  * **数据计数器（DC）**：存放本次要传送的字（节）数。

  DMA方式的工作过程是：CPU接收到I/O设备的DMA请求时，它给DMA控制器发出一条命令，同时设置MAR和DC初值，启动DMA控制器，然后继续其他工作。之后CPU就把控制操作委托给DMA控制器，由该控制器负责处理。DMA控制器直接与存储器交互，传送整个数据块，每次传送一个字，这个过程不需要CPU参与。传送完成后，DMA控制器发送一个**中断信号**给处理器。因此只有在传送开始和结束时才需要CPU的参与。

  DMA方式与中断方式的主要区别是，中断方式在**每个数据需要传输时**中断CPU，而DMA方式则是在所要求传送的**一批数据全部传送结束时**才中断CPU；此外，中断方式的数据传送是在中断处理时由CPU控制完成的，而DMA方式则是在DMA控制器的控制下完成的。

* **通道控制方式***：I/O通道是指专门负责输入/输出的处理机。I/O通道方式是DMA方式的发展，它可以进一步减少CPU的干预，即把对一个数据块的读（或写）为单位的干预，减少为对**一组数据块**的读（或写）及有关控制和管理为单位的干预。同时，又可以实现CPU、通道和I/O设备三者的**并行操作**，从而更有效地提高整个系统的资源利用率。 

  当CPU要完成一组相关的读（或写）操作及有关控制时，只需向I/O通道发送一条I/O指令，以给出其所要执行的通道程序的首地址和要访问的I/O设备，通道接到该指令后，执行通道程序便可完成CPU指定的I/O任务，数据传送结束时向CPU发中断请求。

  I/O通道与一般处理机的区别是：通道指令的类型单一，没有自己的内存，通道所执行的通道程序是放在主机的内存中的，也就是说通道与CPU**共享内存**。

  I/O通道与DMA方式的区别是：DMA方式需要CPU来控制传输的数据块大小、传输的内存位置，而通道方式中这些信息是**由通道控制**的（通道拥有更高的自主权）。另外，每个**DMA控制器**对应**一台设备**与内存传递数据，而一个**通道**可以控制**多台设备**与内存的数据交换。

### 5.1.3 I/O软件层次结构

I/O软件往下与硬件有着密切关系，往上与虚拟存储器系统、文件系统和用户直接交互，它们都需要I/O软件来实现I/O操作。

为使复杂的I/O软件能具有清晰的结构、良好的可移植性和易适应性，目前已普遍采用**层次式结构**的I/O软件。将系统中的设备管理模块分为若干个层次，每层都是利用其下层提供的服务，完成输入/输出功能中的某些子功能，并**屏蔽这些功能实现的细节**，向高层提供服务。在层次式结构的I/O软件中，只要层次间的接口不变，对某一层次中的软件的修改都不会引起其下层或高层代码的变更，**仅最低层才涉及硬件的具体特性**。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241010192451142.png?token=AVQM64IYST3MKENDURXT6MDHFIX6M" alt="image-20241010192451142" style="zoom:67%;" />

一个比较合理的层次划分如上图所示。整个I/O软件可以视为具有4个层次的系统结构。

* **用户层I/O软件**：实现与用户交互的接口，用户可直接调用在用户层提供的、与I/O操作有关的库函数，对设备进行操作。一般而言，大部分的I/O软件都在操作系统内部，但仍有一小部分在用户层，包括与用户程序链接在一起的库函数。用户层软件必须通过一组**系统调用**来获取操作系统服务。

* **设备独立性软件**：用于实现用户程序与设备驱动器的统一接口、设备命令、设备的保护及设备的分配与释放等，同时为设备管理和数据传送提供必要的存储空间。 

  设备独立性也称**设备无关性**，使得*应用程序独立于具体使用的物理设备*。为实现设备独立性而引入了逻辑设备和物理设备这两个概念。在**应用程序**中，使用**逻辑设备名**来请求使用某类设备；而在**系统实际执行**时，必须将逻辑设备名映射成**物理设备名**使用。 

  使用逻辑设备名的好处是：①增加设备分配的灵活性；②易于实现I/O重定向，所谓I/O重定向，是指用于I/O操作的设备可以更换，而不必改变应用程序。 

  为了实现设备独立性，必须再在驱动程序之上设置一层设备独立性软件。总体而言，设备独立性软件的主要功能可分为以下两个方面：①执行所有设备的公有操作。②向用户层（或文件层）提供统一接口。例如，对各种设备的读/写操作，在应用程序中都统一使用read/write命令等。

* **设备驱动程序**：与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动I/O设备工作的驱动程序。 通常，每类设备配置一个设备驱动程序，它是I/O进程与设备控制器之间的通信程序，通常以**进程**的形式存在。设备驱动程序向上层用户程序提供一组标准接口，设备具体的差别被设备驱动程序所封装，用于接收上层软件发来的**抽象I/O要求**，如read和write命令，**转换为具体要求**后，**发送给设备控制器**，控制I/O设备工作；它也将由设备控制器发来的信号传送给上层软件，从而为I/O内核子系统隐藏设备控制器之间的差异。

* **中断处理程序**：用于保存被中断进程的CPU环境，转入相应的中断处理程序进行处理，处理完毕再恢复被中断进程的现场后，返回到被中断进程。 

  由于中断处理与硬件紧密相关，对用户而言，应尽量加以屏蔽，因此应放在操作系统的底层，系统的其余部分尽可能少地与之发生联系。 

通过用户对设备的一次命令来记忆I/O软件层次：

①当用户要读取某设备的内容时，通过操作系统提供的read命令接口，这就经过了用户层。

②操作系统提供给用户使用的接口，一般是统一的通用接口，也就是几乎每个设备都可以响应的统一命令，如read命令，用户发出的read命令，首先经过设备独立层进行解析，然后交往下层。

③接下来，不同类型的设备对read命令的行为会有所不同。因此，需要针对不同的设备，把read命令解析成不同的指令，这就经过了设备驱动层。

④命令解析完毕后，需要中断正在运行的进程，转而执行read命令，这就需要中断处理程序。

⑤最后，命令真正抵达硬件设备，硬件设备的控制器按照上层传达的命令操控硬件设备，完成相应的功能。

### 5.1.4 应用程序I/O接口

在I/O系统与高层之间的接口中，根据设备类型的不同，又进一步分为若干接口。

* **字符设备接口**：字符设备是指数据的存取和传输是以字符为单位的设备，如键盘、打印机等。基本特征是传输速率较低、不可寻址，并且在输入/输出时通常采用**中断驱动**方式。

  * get和put操作：由于字符设备**不可寻址**，只能采取**顺序存取**方式，通常为字符设备建立一个字符缓冲区，用户程序通过get操作从缓冲区获取字符，通过put操作将字符输出到缓冲区。
  * in-control指令：字符设备类型繁多，差异甚大，因此在接口中提供一种通用的in-control指令来处理它们（包含了许多参数，每个参数表示一个与具体设备相关的特定功能）。 
  * 字符设备都属于**独占设备**，为此接口中还需要提供打开和关闭操作，以实现互斥共享。

* **块设备接口**：块设备是指数据的存取和传输是以数据块为单位的设备，典型的块设备是磁盘。基本特征是传输速率较高、可寻址。磁盘设备的I/O常采用**DMA**方式。

  * 隐藏了磁盘的二维结构。在二维结构中，每个扇区的地址需要用磁道号和扇区号来表示。块设备接口将磁盘的所有扇区从0到n-1依次编号，这样，就将二维结构变为一种线性序列。 
  * 将抽象命令映射为低层操作。块设备接口支持上层发来的对文件或设备的打开、读、写和关闭等抽象命令，该接口将上述命令映射为设备能识别的较低层的具体操作。
  * 内存映射接口通过内存的字节数组来访问磁盘，而不提供读/写磁盘操作。映射文件到内存的系统调用返回包含文件副本的一个虚拟内存地址。只在需要访问内存映像时，才由虚拟存储器实际调页。内存映射文件的访问如同内存读写一样简单，极大地方便了程序员。

* **网络设备接口**：现代操作系统都提供面向网络的功能，因此还需要提供相应的网络软件和网络通信接口，使计算机能够通过网络与网络上的其他计算机进行通信或上网浏览。 

  许多操作系统提供的网络I/O接口为网络套接字接口，套接字接口的系统调用使应用程序创建的本地套接字连接到远程应用程序创建的套接字，通过此连接发送和接收数据。

* **阻塞/非阻塞I/O**：操作系统的I/O接口还涉及两种模式：**阻塞**和**非阻塞**。 

  阻塞I/O是指当用户进程调用I/O操作时，进程就被阻塞，需要等待I/O操作完成，进程才被唤醒继续执行。非阻塞I/O是指用户进程调用I/O操作时，不阻塞该进程，该I/O调用返回一个错误返回值，通常，进程需要通过轮询的方式来查询I/O操作是否完成。 大多数操作系统提供的I/O接口都是采用阻塞I/O。

## 5.2 设备独立性软件

### 5.2.1 与设备无关的软件

与设备无关的软件是I/O系统的最高层软件，它的下层是设备驱动程序，其间的界限因操作系统和设备的不同而有所差异。总体而言，设备独立性软件包括执行所有设备公有操作的软件。

### 5.2.2 高速缓存与缓冲区

* **磁盘高速缓存（Disk Cache）**：操作系统中使用磁盘高速缓存技术来提高磁盘的I/O速度，对访问高速缓存要比访问原始磁盘数据更为高效。例如，正在运行进程的数据既存储在磁盘上，又存储在物理内存上，也被复制到CPU的二级和一级高速缓存中。不过，磁盘高速缓存技术不同于通常意义下的介于CPU与内存之间的小容量高速存储器，而是指利用**内存**中的存储空间来暂存从磁盘中读出的一系列盘块中的信息。因此，**磁盘高速缓存逻辑上属于磁盘，物理上则驻留在内存中的盘块**。 

  高速缓存在内存中分为两种形式：一种是在内存中**开辟一个单独的空间**作为磁盘高速缓存，大小固定；另一种是把**未利用的内存空间**作为一个缓冲池，供请求分页系统和磁盘I/O时共享。

* **缓冲区（Buffer）**：在设备管理子系统中，引入缓冲区的目的主要如下：

  * 缓和CPU与I/O设备间速度不匹配的矛盾。
  * 减少对CPU的中断频率，放宽对CPU中断响应时间的限制。
  * 解决基本数据单元大小（即数据粒度）不匹配的问题。
  * 提高CPU和I/O设备之间的并行性。 

  其实现方法如下：

  * 采用硬件缓冲器，但由于成本太高，除一些关键部位外，一般不采用硬件缓冲器。
  * 采用缓冲区（**位于内存区域**）。 

  根据系统设置缓冲器的个数，缓冲技术可以分为如下几种：

  * **单缓冲**：在主存中设置一个缓冲区。当设备和处理机交换数据时，先将数据写入缓冲区，然后需要数据的设备或处理机从缓冲区取走数据，在缓冲区写入或取出的过程中，另一方需等待。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012170152338.png?token=AVQM64LPWEMITPGH2PZEA7LHFIX6Q" alt="image-20241012170152338" style="zoom:67%;" />

    在块设备输入时，假定从磁盘把一块数据输入到缓冲区的时间为T，操作系统将该缓冲区中的数据传送到用户区的时间为M，而CPU对这一块数据处理的时间为C。 

    在研究每块数据的处理时间时，有一个技巧：假设一种初始状态，然后计算下一次到达相同状态时所需要的时间，就是处理一块数据所需要的时间。在单缓冲中，这种初始状态为：工作区是满的，缓冲区是空的。 如题目无明确说明，通常认为缓冲区的大小和工作区的大小相等。 

    假设T > C，从初始状态开始，当工作区数据处理完后，时间为C，缓冲区还没充满，当缓冲区充满时，经历了 T时间，停止再冲入数据，然后缓冲区向工作区传送数据，当工作区满了后， 缓冲区的数据同时也为空，用时为M，到达下一个开始状态，整个过程用时M + T；若T < C，同理，整个过程用时M + C。故单缓冲区处理每块数据的用时为**max(C, T) + M**。

  * **双缓冲**：根据单缓冲的特点，CPU在传送时间M内处于空闲状态，由此引入双缓冲。I/O设备输入数据时先装填到缓冲区1，在缓冲区1填满后才开始装填缓冲区2, 与此同时处理机可以从缓冲区1中取出数据送入用户进程，当缓冲区1中的数据处理完后，若缓冲区2己填满，则处理机又从缓冲区2中取出数据送入用户进程，而I/O设备又可以装填缓冲区。注意，必须等缓冲区2充满才能让处理机从缓冲区2取出数据。双缓冲机制提高了处理机和输入设备的并行程度。 

    为了研究双缓冲处理一块数据的用时，我们先规定一种初始状态：工作区是空的，其中一个缓冲区是满的，另外一个缓冲区是空的；我们不妨假设缓冲区1是空的，缓冲区2是满的。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012171106295.png?token=AVQM64LHSK7T7ACVP6R7NNDHFIX6U" alt="image-20241012171106295" style="zoom:67%;" />

    双缓冲区处理一块数据的用时为**max(C + M, T)**。 

    若两台机器之间通信仅配置了单缓冲，则它们在任意时刻都只能实现单方向的数据传输。例如，只允许把数据从A机传送到B机，或从B机传送到A机，而绝不允许双方同时向对方发送数据。为了实现双向数据传输，必须在两台机器中都设置两个缓冲区，一个用作发送缓冲区，另一个用作接收缓冲区。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012172050728.png?token=AVQM64KMSMFQ55QK4LCYGJLHFIX6W" alt="image-20241012172050728" style="zoom:67%;" />

  * **循环缓冲**：包含多个大小相等的缓冲区，每个缓冲区中有一个链接指针指向下一个缓冲区，最后一个缓冲区指针指向第一个缓冲区，多个缓冲区构成一个环形。

    循环缓冲用于输入/输出时，还需要有两个指针in和out。对输入而言，首先要从设备接收数据到缓冲区中，in指针指向可以输入数据的第一个空缓冲区；当运行进程需要数据时，从循环缓冲区中取一个装满数据的缓冲区，并从此缓冲区中提取数据，out指针指向可以提取数据的第一个满缓冲区。输出则正好相反。

  * **缓冲池**：由多个系统**公用**的缓冲区组成，缓冲区按其使用状况可以形成三个队列：**空缓冲队列**、装满输入数据的缓冲队列（**输入队列**）和装满输出数据的缓冲队列（**输出队列**）。还应具有4种缓冲区：用于收容输入数据的工作缓冲区、用于提取输入数据的工作缓冲区、用于收容输出数据的工作缓冲区及用于提取输出数据的工作缓冲区。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012172130011.png?token=AVQM64MC3HLOX54ODTIOAHDHFIX6Y" alt="image-20241012172130011" style="zoom:67%;" />

    当输入进程需要输入数据时，便从空缓冲队列的队首摘下一个空缓冲区，把它作为收容输入工作缓冲区，然后把输入数据输入其中，装满后再将它挂到输入队列队尾。当计算进程需要输入数据时，便从输入队列取得一个缓冲区作为提取输入工作缓冲区，计算进程从中提取数据/数据用完后再将它挂到空缓冲队列尾。当计算进程需要输出数据时，便从空缓冲队列的队首取得一个空缓冲区，作为收容输出工作缓冲区，当其中装满输出数据后，再将它挂到输出队列队尾。当要输出时，由输出进程从输出队列中取得一个装满输出数据的缓冲区，作为提取输出工作缓冲区， 当数据提取完后，再将它挂到空缓冲队列的队尾。 

* 高速缓存与缓冲区的对比

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012172706920.png?token=AVQM64IX2CZB7PCIAF3MMNLHFIX64" alt="image-20241012172706920" style="zoom:67%;" />

### 5.2.3 设备分配与回收

* 设备分配概述：设备分配是指根据用户的I/O请求分配所需的设备。分配的总原则是充分发挥设备的使用效率，尽可能地让设备忙碌，又要避免由于不合理的分配方法造成进程死锁。从设备的特性来看， 采用下述三种使用方式的设备分别称为**独占设备**、**共享设备**和**虚拟设备**。

  * 独占式使用设备。进程分配到独占设备后，便由其独占，直至该进程释放该设备。
  * 分时式共享使用设备。对于共享设备，可同时分配给多个进程，通过分时共享使用。
  * 以SPOOLing方式使用外部设备。SPOOLing技术实现了虚拟设备功能，可以将设备同时分配给多个进程。这种技术实质上就是**实现了对设备的I/O操作的批处理**。

* **设备分配的数据结构**：设备分配依据的主要数据结构有**设备控制表**（DCT）、**控制器控制表**（COCT）、**通道控制表**（CHCT）和**系统设备表**（SDT）。

  * **设备控制表（DCT）**：一个设备控制表就表征一个设备，而这个控制表中的表项就是设备的各个属性。凡因请求本设备而未得到满足的进程，应将其PCB按某种策略排成一个设备请求队列，设备队列的队首指针指向该请求队列队首PCB。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012173537494.png?token=AVQM64NB5LB7BWD54VHET6LHFIX66" alt="image-20241012173537494" style="zoom:67%;" />

  * **控制器控制表（COCT）和通道控制表（CHCT）**：设备控制器控制设备与内存交换数据，而设备控制器又需要请求通道为它服务，因此每个COCT有一个表项存放指向相应CHCT的指针，而一个通道可为多个设备控制器服务，因此CHCT中必定有一个指针，指向一个表，这个表上的信息表达的是CHCT提供服务的那几个设备控制器。CHCT与COCT的关系是**一对多**的关系。

  * **系统设备表（SDT）**：整个系统只有一张SDT。它记录己连接到系统中的所有物理设备的情况，每个物理设备占一个表目。

    <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012173928689.png?token=AVQM64JY3EDHRNGSUBDM35LHFIX7C" alt="image-20241012173928689" style="zoom:67%;" />

* **设备分配的策略**：

  * **设备分配原则**：设备分配应根据设备特性、用户要求和系统配置情况。既要充分发挥设备的使用效率，又要避免造成进程死锁，还要将用户程序和具体设备隔离开。

  * **设备分配方式**：有静态分配和动态分配两种。

    * **静态分配**：主要用于对独占设备的分配，它在用户作业开始执行前，由系统一次性分配该作业所要求的全部设备、 控制器。一旦分配，这些设备、控制器就一直为该作业所占用，直到该作业被撤销。静态分配方式不会出现死锁，但设备的**使用效率低**。
    * **动态分配**：在进程执行过程中根据执行需要进行。当进程需要设备时，通过系统调用命令向系统提出设备请求，由系统按某种策略给进程分配所需要的设备、控制器，一旦用完，便立即释放。这种方式有利于提高设备利用率，但若分配算法使用不当，则有**可能造成进程死锁**。

  * **设备分配算法**：常用的动态设备分配算法有先请求先分配、优先级高者优先等。 

    对于**独占设备**，既可以采用动态分配方式，又可以采用静态分配方式，但往往采用**静态分配方式**。**共享设备**可被多个进程所共享，一般采用**动态分配方式**，但在每个I/O传输的单位时间内只被一个进程所占有，通常采用**先请求先分配**和**优先级高者优先**的分配算法。

* **设备分配的安全性**：指设备分配中应防止发生进程死锁。
  * **安全分配方式**。每当进程**发出I/O请求后便进入阻塞态**，直到其**I/O操作完成时才被唤醒**。 这样，一旦进程己经获得某种设备后便阻塞，不能再请求任何资源，而在它阻塞时也不保持任何资源。其优点是设备分配安全，缺点是CPU和I/O设备是**串行工作**的。
  * **不安全分配方式**。进程在发出I/O请求后仍继续运行，需要时又发出第二个、第三个I/O请求等。仅当进程所请求的**设备已被另一进程占用时，才进入阻塞态**。优点是一个进程可同时操作多个设备，使进程推进迅速；缺点是有可能造成死锁。
* **逻辑设备名到物理设备名的映射**：为了实现设备独立性，在应用程序中使用逻辑设备名来请求使用某类设备，在系统中设置一张**逻辑设备表（Logical Unit Table, LUT）**，用于将逻辑设备名映射为物理设备名。LUT表项包括逻辑设备名、物理设备名和设备驱动程序入口地址；当进程用逻辑设备名来请求分配设备时，系统为它分配一台相应的物理设备，并在LUT中建立一个表目，当以后进程再利用该逻辑设备名请求I/O操作时，系统通过查找LUT来寻找对应的物理设备和驱动程序。 在系统中可采取两种方式设置逻辑设备表：
  * 在整个系统中只设置一张LUT。这样，所有进程的设备分配情况都记录在同一张LUT中， 因此不允许LUT中具有相同的逻辑设备名，主要适用于单用户系统。
  * 为每个用户设置一张LUT。每当用户登录时，系统便为该用户**建立一个进程**，同时也为之建立一张LUT，并将该表**放入进程的PCB中**。

### 5.2.4 SPOOLing技术（假脱机技术）

为了缓和CPU的高速性与I/O设备低速性之间的矛盾，引入了脱机输入/输出技术，它是操作系统中采用的一项**将独占设备改造成共享设备**的技术。该技术利用专门的外围控制机，将低速I/O设备上的数据传送到高速磁盘上，或者相反。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241012180904227.png?token=AVQM64NE44VX5QTQJBRAIS3HFIX7G" alt="image-20241012180904227" style="zoom:67%;" />

* **SPOOLing系统的组成**：

  * **输入井和输出井**：在**磁盘**上开辟出的两个存储区域。输入井模拟脱机输入时的磁盘，用于收容I/O设备输入的数据。输出井模拟脱机输出时的磁盘，用于收容用户程序的输出数据。一个进程的输入（或输出）数据保存为一个文件，所有进程的数据输入（或输出）文件链接成一个输入（或输出）队列。

  * **输入缓冲区和输出缓冲区**：在**内存**中开辟的两个缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用于暂存从输出井送来的数据，以后再传送到输出设备。

  * **输出进程和输出进程**：输入/输出进程用于模拟脱机输入/输出时的外围控制机。用户要求的数据从输入设备经过输入缓冲区送到输入井，当CPU需要输入数据时，直接**从输入井读入内存**。用户要求输出的数据先**从内存送到输出井**，待输出设备空闲时，再将输出井中的数据经过输出缓冲区送到输出设备。**共享打印机**是使用SPOOLing技术的实例。当用户进程请求打印输出时，SPOOLing系统同意打印，但是并不真正立即把打印机分配给该进程，而由假脱机管理进程完成两项任务：

    * 在磁盘缓冲区中为之申请一个空闲盘块，并将要打印的数据送入其中暂存。
    * 为用户进程申请一张空白的用户请求打印表，并将用户的打印要求填入其中，再将该表挂到假脱机文件队列上。 

    这两项工作完成后，虽然还没有任何实际的打印输出，但是对于用户进程而言，其打印任务已完成。对用户而言，系统并非立即执行真实的打印操作，而只是立即将数据输出到缓冲区，真正的打印操作是在打印机空闲且该打印任务已排在等待队列队首时进行的。

* **SPOOLing系统的特点**：

  * 提高了I/O速度，缓和了 CPU和低速I/O设备之间的速度不匹配的矛盾；
  * 将独占设备改造为共享设备，在假脱机打印机系统中，实际上并没有为任何进程分配设备；
  * 实现了虚拟设备功能，对每个进程而言，它们都认为自己独占了一个设备。 

SPOOLing技术是一种**以空间换时间**的技术，它开辟了磁盘上的空间作为输入井和输出井，牺牲了空间。在SPOOLing技术下，CPU要打印机打印的数据可以先输出到磁盘的输出井中（这个过程由假脱机进程控制），然后做其他的事情。若打印机此时被占用，则SPOOLing系统就会把这个打印请求挂到等待队列上，待打印机有空时再把数据打印出来。向磁盘输出数据的速度比向打印机输出数据的速度快，因此就节省了时间。

### 5.2.5 设备驱动程序接口

如果每个设备驱动程序与操作系统的接口都不同，那么每次出现一个新设备时，都必须为此修改操作系统。因此，要求每个设备驱动程序与操作系统之间都有着相同或相近的接口。这样会使得添加一个新设备驱动程序变得很容易，同时也便于开发人员编制设备驱动程序。 

对于每种设备类型，例如磁盘，操作系统都要定义一组驱动程序必须支持的**函数**。对磁盘而言，这些函数自然包含读、写、格式化等。驱动程序中通常包含一张**表格**，这张表格具有针对这些**函数指向驱动程序自身的指针**。装载驱动程序时，操作系统记录这个函数指针表的地址，所以当操作系统需要调用一个函数时，它可以通过这张表格发出**间接调用**。这个函数指针表定义了驱动程序与操作系统其余部分之间的接口。给定类型的所有设备都必须服从这一要求。 

与设备无关的软件还要负责将符号化的设备名映射到适当的驱动程序上。例如，在UNIX中，设备名/dev/disk0唯一确定了一个特殊文件的i结点，这个i结点包含了主设备号（用于定位相应的驱动程序）和次设备号（用来确定要读写的具体设备）。 

在UNIX和Windows中，设备是作为命名对象出现在文件系统中的，因此针对文件的常规保护规则也适用于I/O设备。系统管理员可以为每个设备设置适当的访问权限。

## 5.3 磁盘和固态硬盘

### 5.3.1 磁盘

**磁盘（Disk）**是由表面涂有磁性物质的物理盘片，通过一个称为**磁头**的导体线圈从磁盘存取数据。在读/写操作期间，磁头固定，磁盘在下面高速旋转。磁盘盘面上的数据存储在一组同心圆中，称为**磁道**。每个磁道与磁头一样宽，一个盘面有上千个磁道。磁道又划分为几百个**扇区**，每个扇区固定存储大小，一个扇区称为一个**盘块**。相邻磁道及相邻扇区间通过一定的间隙分隔开，以避免精度错误。注意，由于扇区按固定圆心角度划分，所以密度从最外道向里道增加，**磁盘的存储能力受限于最内道的最大记录密度**。 

磁盘安装在一个磁盘驱动器中，它由磁头臂、用于旋转磁盘的主轴和用于数据输入/输出的电子设备组成。多个盘片垂直堆叠，组成磁盘组，每个盘面对应一个磁头，所有磁头固定在一起，与磁盘中心的距离相同且一起移动。所有盘片上相对位置相同的磁道组成**柱面**。 **扇区是磁盘可寻址的最小单位**，磁盘上能存储的物理块数目由扇区数、磁道数及磁盘面数决定， 磁盘地址用“柱面号 • 盘面号 • 扇区号”表示。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241013150152236.png?token=AVQM64JH4YCS54IK4YX6D6DHFIX7I" alt="image-20241013150152236" style="zoom:67%;" />

磁盘按不同的方式可分为若干类型：磁头相对于盘片的径向方向固定的，称为**固定头磁盘**， 每个磁道一个磁头；磁头可移动的，称为**活动头磁盘**，磁头臂可来回伸缩定位磁道；磁盘永久固定在磁盘驱动器内的，称为**固定盘磁盘**；可移动和替换的，称为**可换盘磁盘**。 

操作系统中几乎每介绍一类资源及其管理时，都要涉及一类调度算法。用户访问文件，需要操作系统的服务，文件实际上存储在磁盘中，操作系统接收用户的命令后，经过一系列的检验访问权限和寻址过程后，最终都会到达磁盘，控制磁盘把相应的数据信息读出或修改。当有多个请求同时到达时，操作系统就要决定先为哪个请求服务，这就是磁盘调度算法要解决的问题。

### 5.3.2 磁盘的管理

* **磁盘初始化**：新的磁盘只是一个空白盘。在磁盘可以存储数据之前，必须将它分成扇区，以便磁盘控制器能够进行读写操作，这个过程称为**低级格式化**（或称**物理格式化**）。低级格式化为每个扇区使用特殊的**数据结构**，填充磁盘。每个扇区的数据结构通常由**头部、数据区域（通常为512B大小）和尾部**组成。头部和尾部包含了一些磁盘控制器的使用信息。 

  大多数磁盘在工厂时作为制造过程的一部分就己低级格式化，这种格式化能够让制造商测试磁盘，并且初始化逻辑块号到无损磁盘扇区的映射。对于许多磁盘，当磁盘控制器低级格式化时，还能指定在头部和尾部之间留下多长的数据区，通常选择256或512字节等。

* **分区**：在可以使用磁盘存储文件之前，操作系统还要将自己的数据结构记录到磁盘上，分为两步： 第一步是，将磁盘分为由一个或多个柱面组成的分区（即我们熟悉的C盘、D盘等形式的分区），每个分区的起始扇区和大小都记录在磁盘主引导记录的分区表中；第二步是，对物理分区进行**逻辑格式化**（**创建文件系统**），操作系统将初始的文件系统数据结构存储到磁盘上，这些数据结构包括空闲空间和己分配的空间以及一个初始为空的目录。 

  因扇区的单位太小，为了提高效率，操作系统将多个相邻的扇区组合在一起，形成一**簇**（在Linux中称为**块**）。为了更高效地管理磁盘，一簇只能存放一个文件的内容，**文件所占用的空间只能是簇的整数倍**；如果文件大小小于一簇（甚至是0字节），也要占用一簇的空间。

* **引导块**：计算机启动时需要运行一个初始化程序（**自举程序**），它初始化CPU、寄存器、设备控制器和内存等，接着启动操作系统。为此，自举程序找到磁盘上的操作系统内核，将它加载到内存， 并转到起始地址，从而开始操作系统的运行。 

  自举程序通常存放在ROM中，为了避免改变自举代码而需要改变ROM硬件的问题，通常只在ROM中保留很小的自举装入程序，而将完整功能的引导程序保存在磁盘的启动块上，启动块位于磁盘的固定位置。具有启动分区的磁盘称为**启动磁盘**或**系统磁盘**。 

  引导ROM中的代码指示磁盘控制器将引导块读入内存，然后开始执行，它可以从非固定的磁盘位置加载整个操作系统，并且开始运行操作系统。下面以Windows为例来分析引导过程。Windows允许将磁盘分为多个分区，有一个分区为**引导分区**，它包含操作系统和设备驱动程序。Windows系统将引导代码存储在磁盘的第0号扇区，它称为**主引导记录（MBR）**。引导首先运行ROM中的代码，这个代码指示系统从MBR中读取引导代码。 除了包含引导代码，MBR还包含：一个磁盘分区表和一个标志（以指示从哪个分区引导系统）。当系统找到引导分区时，读取分区的第一个扇区，称为**引导扇区**，并继续余下的引导过程，包括加载各种系统服务。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241013152223533.png?token=AVQM64NYX5SGM7AXBX2CSXDHFIX7K" alt="image-20241013152223533" style="zoom:67%;" />

* **坏块**：由于磁盘有移动部件且容错能力弱，因此容易导致一个或多个扇区损坏。部分磁盘甚至在出厂时就有坏块。根据所用的磁盘和控制器，对这些块有多种处理方式。 

  对于简单磁盘，如采用IDE控制器的磁盘，坏块可手动处理，如MS-DOS的Format命令执行逻辑格式化时会扫描磁盘以检查坏块。坏块在FAT表上会标明，因此程序不会使用它们。 

  对于复杂的磁盘，控制器维护磁盘内的坏块列表。这个列表在出厂低级格式化时就已初始化,并在磁盘的使用过程中不断更新。低级格式化将一些块保留作为备用，操作系统看不到这些块。 控制器可以采用备用块来逻辑地替代坏块，这种方案称为**扇区备用**。 

  对坏块的处理实质上就是用某种机制使系统不去使用坏块。

### 5.3.3 磁盘调度算法

一次磁盘读写操作的时间由寻道时间、旋转延迟时间和传输时间决定。

* **寻找时间** $T_s$：活动头磁盘在读写信息前，将磁头移动到指定磁道所需要的时间。这个时间除跨越n条磁道的时间外，还**包括启动磁臂的时间**s，即
  $$
  T_s=m\times n +s
  $$
  式中，m是与磁盘驱动器速度有关的常数，约为0.2ms，磁臂的启动时间约为2ms。

* **旋转延迟时间** $T_r$：磁头定位到某一磁道的扇区所需要的平均时间，设磁盘的旋转速度为r，则
  $$
  T_r=\frac{1}{2r}
  $$
  对于硬盘，典型的旋转速度为5400转/分，相当于一周11.1ms，则$T_r$为5.55ms；对于软盘，其旋转速度为300〜600转/分，则$T_r$为50〜100ms。

* **传输时间 ** $T_t$：从磁盘读出或向磁盘写入数据所经历的时间，这个时间取决于每次所读/写的字节数b和磁盘的旋转速度：
  $$
  T_t=\frac{b}{rN}
  $$
  式中，r为磁盘每秒的转数，N为一个磁道上的字节数。 在磁盘存取时间的计算中，寻道时间与磁盘调度算法相关；而延迟时间和传输时间都与磁盘旋转速度相关，且为线性相关，所以在硬件上，转速是磁盘性能的一个非常重要的参数。 

**总平均存取时间**$T_a$可以表示为
$$
T_a=T_s+T_r+T_t=m\times n+s+\frac{1}{2r}+\frac{b}{rN}
$$
这个平均值是没有太大实际意义的，因为在实际的磁盘I/O操作中，存取时间与磁盘调度算法密切相关。

常见的磁盘调度算法有以下几种。

* **FCFS算法**：最简单的调度方法。优点是具有公平性。若只有少量进程需要访问，且大部分请求都是访问簇聚的文件扇区，则有望达到较好的性能：若有大量进程竞争使用磁盘，则这种算法在性能上往往接近于随机调度。所以，实际磁盘调度中会考虑一些更为复杂的调度算法。

  例如，磁盘请求队列中的请求顺序分别为55, 58, 39, 18, 90, 160, 150, 38, 184, 磁头的初始位置是磁道100, 采用FCFS算法时，磁头共移动了(45 + 3 + 19 + 21 +72 + 70+ 10+ 112+ 146)=498 个磁道，平均寻找长度=498/9=55.3。

* **最短寻找时间优先（SSTF）算法**：每次调度处理与当前磁头所在磁道距离最近的磁道，以便每次的寻找时间最短。这种算法会产生"饥饿”现象。

* **扫描（SCAN）算法（电梯调度算法）**：SCAN算法在磁头当**前移动方向上**选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象，实际上就是在最短寻找时间优先算法的基础上规定了磁头运动的方向。 由于磁头移动规律与电梯运行相似，因此又称**电梯调度算法**。SCAN算法对最近扫描过的区域不公平，因此它在访问**局部性**方面不如FCFS算法和SSTF算法好。

* **循环扫描（C-SCAN）算法**：在扫描算法的基础上规定磁头单向移动来提供服务，**回返时直接快速移动至起始端**而不服务任何请求。由于SCAN算法偏向于处理那些接近最里或最外的磁道的访问请求，所以使用改进型的C-SCAN算法来避免这个问题。

* 采用SCAN算法和C-SCAN算法时，磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要**到达最远端的一个请求即可返回**，不需要到达，磁盘端点。 这种形式的SCAN算法和C-SCAN算法称为**LOOK调度**和**C-LOOK调度**，因为它们在朝一个给定方向移动前会查看是否有请求。

对比以上几种磁盘调度算法，FCFS算法太过简单，性能较差，仅在请求队列长度接近于1时才较为理想；SSTF算法较为通用和自然；SCAN算法和C-SCAN算法在磁盘负载较大时比较占优势。

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241013161755022.png?token=AVQM64I4PKWBU3CWTDIJ2D3HFIX7O" alt="image-20241013161755022" style="zoom:67%;" />

除减少寻找时间外，减少延迟时间也是提高磁盘传输效率的重要因素。可以对**盘面扇区**进行**交替编号**，对磁盘片组中的**不同盘面错位命名**。

磁盘是连续自转设备，磁头读/写一个物理块后，需要经过短暂的处理时间才能开始读/写下一块。假设逻辑记录数据连续存放在磁盘空间中，若在盘面上按扇区交替编号连续存放，则连续读/写多条记录时能减少磁头的延迟时间；同柱面不同盘面的扇区若能错位编号，连续读/写相邻两个盘面的逻辑记录时也能减少磁头延迟时间。 

<img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241013163241443.png?token=AVQM64OJEIPKJXP66V57P53HFIX7S" alt="image-20241013163241443" style="zoom:67%;" />

在随机扇区访问情况下，定位磁道中的一个扇区平均需要转过4个扇区，这时，延迟时间是传输时间的4倍，这是一种非常低效的方式。理想的情况是不需要定位而直接连续读取扇区，没有延迟时间，这样磁盘数据存取效率可以成倍提高。但由于读取扇区的顺序是不可预测的，所以延迟时间不可避免。

磁盘寻块时间分为三个部分，即寻道时间、延迟时间和传输时间，寻道时间和延迟时间属于"找”的时间，凡是“找”的时间都可以通过一定的方法削减，但传输时间是磁盘本身性质所决定的，不能通过一定的措施减少。

### 5.3.4 固态硬盘

* **固态硬盘的特性**：固态硬盘（SSD）是一种基于**闪存技术**的存储器。它**与U盘并无本质差别**，只是容量更大， 存取性能更好。一个SSD由一个或多个**闪存芯片**和**闪存翻译层**组成。闪存芯片替代传统旋转磁盘中的机械驱动器，而闪存翻译层将来自CPU的逻辑块读写请求翻译成对底层物理设备的读写控制信号，因此闪存翻译层相当于扮演了**磁盘控制器**的角色。

  <img src="https://raw.githubusercontent.com/HikasaHana/TyporaImageCloud/main/image-20241013163923345.png?token=AVQM64OC6XVQMMCGBYAPMZTHFIX7W" alt="image-20241013163923345" style="zoom:67%;" />

  图中，一个闪存由B块组成，每块由P页组成。通常，页的大小是512B〜4KB，每块由32〜128页组成，块的大小为16KB〜512KB。数据是以**页**为单位读写的。只有在一页所属的**块整个被擦除后**，才能写这一页。不过，一旦擦除一块，块中的每页就都可以直接再写一次。 *某块进行若干次重复写后，就会磨损坏，不能再使用。* 

  随机写很慢，有两个原因。首先，擦除块比较慢，通常比访问页高一个数量级。其次，如果写操作试图修改包含己有数据的页$P_i$，那么这个块中所有含有用数据的页都必须被复制到一个新（擦除过的）块中，然后才能进行对页$P_i$的写操作。

  比起传统磁盘，SSD有很多优点，它由半导体存储器构成，没有移动的部件，因而**随机访问**速度比机械磁盘要快很多，也没有任何机械噪声和震动，能耗更低、抗震性好、安全性高等。 

* **磨损均衡**：固态硬盘也有缺点，闪存的擦写寿命是有限的，一般是几百次到几千次。如果直接用普通闪存组装SSD，那么实际的寿命表现可能非常令人失望一一读写数据时会集中在SSD的一部分闪存，这部分闪存的寿命会损耗得特别快。*一旦这部分闪存损坏，整块SSD也就损坏了。*这种磨损不均衡的情况，可能会导致一块256GB的SSD，只因数兆空间的闪存损坏而整块损坏。为了弥补SSD的寿命缺陷，引入了磨损均衡。SSD磨损均衡技术大致分为两种：

  * **动态磨损均衡**。写入数据时，自动选择较新的闪存块。老的闪存块先歇一歇。
  * **静态磨损均衡**。这种技术更为先进，就算没有数据写入，SSD也会监测并自动进行数据分配，让老的闪存块承担无须写数据的存储任务，同时让较新的闪存块腾出空间，平常的读写操作在较新的闪存块中进行。如此一来，各闪存块的寿命损耗就都差不多。 

  有了这种算法加持，SSD的寿命就比较可观了。例如，对于一个256GB的SSD，如果闪存的擦写寿命是500次，那么就需要写入125TB数据，才寿终正寝。
